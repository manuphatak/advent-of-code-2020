Reflections
===========

<!--
This file generated by the build script at ./Build.hs from the files in
./reflections.  If you want to edit this, edit those instead!
-->

*[2016][]* / *[2017][]* / *[2018][]* / *[2019][]* / *2020*

[2016]: https://github.com/mstksg/advent-of-code-2016/blob/master/reflections.md
[2017]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md
[2018]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md
[2019]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md

[Available as an RSS Feed][rss]

[rss]: http://feeds.feedburner.com/jle-advent-of-code-2020

Table of Contents
-----------------

* [Day 1](#day-1)
* [Day 2](#day-2)
* [Day 3](#day-3)
* [Day 4](#day-4)
* [Day 5](#day-5)
* [Day 6](#day-6)
* [Day 7](#day-7)
* [Day 8](#day-8)
* [Day 9](#day-9)
* [Day 10](#day-10)
* [Day 11](#day-11)
* [Day 12](#day-12)
* [Day 13](#day-13)
* [Day 14](#day-14)
* [Day 15](#day-15)
* [Day 16](#day-16)
* [Day 17](#day-17)
* [Day 18](#day-18)
* [Day 19](#day-19)

Day 1
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day01.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d01p]* / *[Code][d01g]* / *[Rendered][d01h]* / *[Standalone Reflection Page][d01r]*

[d01p]: https://adventofcode.com/2020/day/1
[d01g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day01.hs
[d01h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day01.html
[d01r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day01.md

So there's a simple-ish Haskell solution for these problems,

`tails` lets you separate out each item in a list with the list of items after
it:

```haskell
ghci> tails [1,2,3,4]
[1:[2,3,4], 2:[3,4], 3:[4], 4:[]]
```

```haskell
findPair :: [Int] -> Maybe Int
findPair xs = listToMaybe $ do
    x:ys <- tails xs
    y    <- ys
    guard (x + y == 2020)
    pure (x*y)

findTriple :: [Int] -> Maybe Int
findTriple xs = listToMaybe $ do
    x:ys <- tails xs
    y:zs <- tails ys
    z    <- zs
    guard (x + y + z == 2020)
    pure (x*y*z)
```

But this method is a little bit "extra", since we actually don't need to search
all of `ys` for the proper sum...if we pick `x` as `500`, then we really only
need to check if `1520` is a part of `ys`.

So we really only need to check for set inclusion:

```haskell
import qualified Data.IntSet as IS

findPair :: Int -> IS.IntSet -> Maybe Int
findPair goal xs = listToMaybe $ do
    x <- IS.toList xs
    let y = goal - x
    guard (y `IS.member` xs)
    pure (x * y)
```

And our first part will be `findPair 2020`!

You could even implement `findTriple` in terms of `findPair`, using `IS.split`
to partition a set into all items smaller than and larger than a number.
Splitting is a very efficient operation on a binary search tree like `IntSet`:

```haskell
findTriple :: Int -> IS.IntSet -> Maybe Int
findTriple goal xs = listToMaybe $ do
    x <- IS.toList xs
    let (_, ys) = IS.split x xs
        goal'   = goal - x
    case findPair goal' ys of
      Nothing -> empty
      Just yz -> pure (x*yz)
```

But hey...this recursive descent is kind of neat.  We could write a general
function to find any goal in any number of items!

```haskell
-- | Given a number n of items and a goal sum and a set of numbers to
-- pick from, finds the n numbers in the set that add to the goal sum.
knapsack
    :: Int              -- ^ number of items n to pick
    -> Int              -- ^ goal sum
    -> IS.IntSet        -- ^ set of options
    -> Maybe [Int]      -- ^ resulting n items that sum to the goal
knapsack 0 _    _  = Nothing
knapsack 1 goal xs
    | goal `IS.member` xs = Just [goal]
    | otherwise           = Nothing
knapsack n goal xs = listToMaybe $ do
    x <- IS.toList xs
    let goal'   = goal - x
        (_, ys) = IS.split x xs
    case knapsack (n - 1) goal' ys of
      Nothing -> empty
      Just rs -> pure (x:rs)
```

And so we have:

```haskell
part1 :: [Int] -> Maybe Int
part1 = knapsack 2 2020 . IS.fromList

part2 :: [Int] -> Maybe Int
part2 = knapsack 3 2020 . IS.fromList
```

And we could go on, and on, and on!

Definitely very unnecessary, but it does shave my time on Part 2 down from
around 2ms to around 20μs :)


### Day 1 Benchmarks

```
>> Day 01a
benchmarking...
time                 6.588 μs   (6.220 μs .. 7.104 μs)
                     0.965 R²   (0.952 R² .. 0.981 R²)
mean                 7.174 μs   (6.897 μs .. 7.499 μs)
std dev              1.142 μs   (928.2 ns .. 1.728 μs)
variance introduced by outliers: 94% (severely inflated)

* parsing and formatting times excluded

>> Day 01b
benchmarking...
time                 48.11 μs   (45.44 μs .. 51.04 μs)
                     0.982 R²   (0.978 R² .. 0.990 R²)
mean                 52.94 μs   (51.31 μs .. 54.51 μs)
std dev              5.165 μs   (4.000 μs .. 6.012 μs)
variance introduced by outliers: 82% (severely inflated)

* parsing and formatting times excluded
```



Day 2
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day02.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d02p]* / *[Code][d02g]* / *[Rendered][d02h]* / *[Standalone Reflection Page][d02r]*

[d02p]: https://adventofcode.com/2020/day/2
[d02g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day02.hs
[d02h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day02.html
[d02r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day02.md

Day 2, not too bad for Haskell either :)

There is some fun in parsing here:

```haskell
data Policy = P
    { pIx1  :: Int
    , pIx2  :: Int
    , pChar :: Char
    , pPass :: String
    }

parsePolicy :: String -> Maybe Policy
parsePolicy str = do
    [ixes,c:_,pwd] <- pure $ words str
    [ix1,ix2]      <- pure $ splitOn "-" ixes
    P <$> readMaybe ix1
      <*> readMaybe ix2
      <*> pure c
      <*> pure pwd
```

I used one of my more regular do-block tricks: if you pattern match in a
`Maybe` do-block, then failed pattern matches will turn the whole thing into a
`Nothing`.  So if any of those list literal pattern matches failed, the whole
block will return `Nothing`.

In any case, we just need to write a function to check if a given policy is
valid for either criteria:

```haskell
countTrue :: (a -> Bool) -> [a] -> Int
countTrue p = length . filter p

validate1 :: Policy -> Bool
validate1 P{..} = n >= pIx1 && n <= pIx2
  where
    n = countTrue (== pChar) pPass

validate2 :: Policy -> Bool
validate2 P{..} = n == 1
  where
    n = countTrue (== pChar) [pPass !! (pIx1 - 1), pPass !! (pIx2 - 1)]
```

And so parts 1 and 2 are just a count of how many policies are true :)

```haskell
part1 :: [Policy] -> Int
part1 = countTrue validate1

part2 :: [Policy] -> Int
part2 = countTrue validate2
```


### Day 2 Benchmarks

```
>> Day 02a
benchmarking...
time                 59.47 μs   (59.46 μs .. 59.49 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 59.56 μs   (59.54 μs .. 59.58 μs)
std dev              73.01 ns   (59.85 ns .. 85.83 ns)

* parsing and formatting times excluded

>> Day 02b
benchmarking...
time                 42.35 μs   (42.33 μs .. 42.38 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 42.38 μs   (42.37 μs .. 42.41 μs)
std dev              57.98 ns   (42.80 ns .. 82.91 ns)

* parsing and formatting times excluded
```



Day 3
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day03.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d03p]* / *[Code][d03g]* / *[Rendered][d03h]* / *[Standalone Reflection Page][d03r]*

[d03p]: https://adventofcode.com/2020/day/3
[d03g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day03.hs
[d03h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day03.html
[d03r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day03.md

Here I'm going to list two methods --- one that involves pre-building a set to
check if a tree is at a given point, and the other involves just a single
direct traversal checking all valid points for trees!

First of all, I'm going to reveal one of my favorite secrets for parsing 2D
ASCII maps!

```haskell
asciiGrid :: IndexedFold (Int, Int) String Char
asciiGrid = reindexed swap (lined <.> folded)
```

This gives you an indexed fold (from the *[lens][]* package) iterating over
each character in a string, indexed by `(x,y)`!

[lens]: https://hackage.haskell.org/package/lens

This lets us parse today's ASCII forest pretty easily into a `Set (Int, Int)`:

```haskell
parseForest :: String -> Set (Int, Int)
parseForest = ifoldMapOf asciiGrid $ \xy c -> case c of
    '#' -> S.singleton xy
    _   -> S.empty
```

This folds over the input string, giving us the `(x,y)` index and the character
at that index.  We accumulate with a monoid, so we can use a `Set (Int, Int)`
to collect the coordinates where the character is `'#'` and ignore all other
coordinates.

Admittedly, `Set (Int, Int)` is sliiiightly overkill, since you could probably
use `Vector (Vector Bool)` or something with `V.fromList . map (V.fromList .
(== '#')) . lines`, and check for membership with double-indexing.  But I was
bracing for something a little more demanding, like having to iterate over all
the trees or something.  Still, sparse grids are usually my go-to data
structure for Advent of Code ASCII maps.

Anyway, now we need to be able to traverse the ray.  We can write a function to
check all points in our line, given the slope (delta x and delta y):

```haskell
countTrue :: (a -> Bool) -> [a] -> Int
countTrue p = length . filter p

countLine :: Int -> Int -> Set (Int, Int) -> Int
countLine dx dy pts = countTrue valid [0..322]
  where
    valid i = (x, y) `S.member` pts
      where
        x = (i * dx) `mod` 31
        y = i * dy
```

And there we go :)

```haskell
part1 :: Set (Int, Int) -> Int
part1 = countLine 1 3

part2 :: Set (Int, Int) -> Int
part2 pts = product $
    [ countLine 1 1
    , countLine 3 1
    , countLine 5 1
    , countLine 7 1
    , countLine 1 2
    ] <*> [pts]
```

Note that this checks a lot of points we wouldn't normally need to check: any y
points out of range (322) for `dy > 1`.  We could add a minor optimization to
only check for membership if `y` is in range, but because our check is a set
lookup, it isn't too inefficient and it always returns `False` anyway.  So a
small price to pay for slightly more clean code :)

So this was the solution I used to submit my original answers, but I started
thinking the possible optimizations.  I realized that we could actually do the
whole thing in a single traversal...since we could associate each of the points
with coordinates as we go along, and reject any coordinates that would not be
on the line!

We can write a function to check if a coordinate is on a line:

```haskell
validCoord
    :: Int      -- ^ dx
    -> Int      -- ^ dy
    -> (Int, Int)
    -> Bool
validCoord dx dy = \(x,y) ->
    let (i,r) = y `divMod` dy
    in  r == 0 && (dx * i) `mod` 31 == x
```

And now we can use `lengthOf` with the coordinate fold up there, which counts
how many traversed items match our fold:

```haskell
countLineDirect :: Int -> Int -> String -> Int
countLineDirect dx dy = lengthOf (asciiGrid . ifiltered tree)
  where
    checkCoord = validCoord dx dy
    tree pt c = c == '#' && checkCoord pt
```

And this gives the same answer, with the same interface!

```haskell
part1 :: String -> Int
part1 = countLineDirect 1 3

part2 :: String -> Int
part2 pts = product $
    [ countLineDirect 1 1
    , countLineDirect 3 1
    , countLineDirect 5 1
    , countLineDirect 7 1
    , countLineDirect 1 2
    ] <*> [pts]
```

Is the direct single-traversal method any faster?

Well, it's complicated, slightly.  There's a clear benefit in the pre-built set
method for part 2, since we essentially build up an efficient structure (`Set`)
that we re-use for all five lines.  We get the most benefit if we build the set
once and re-use it many times, since we only have to do the actual coordinate
folding once.

So, directly comparing the two methods, we see the single-traversal as
faster for part 1 and slower for part 2.

However, we can do a little better for the single-traversal method.  As it
turns out, the lens indexed fold is kind of slow.  I was able to write the
single-traversal one a much faster way by directly just using `zip [0..]`,
without losing too much readability.  And with this *direct* single traversal
and computing the indices manually, we get a much faster time for part 1 (about
ten times faster!) and a slightly faster time for part 2 (about 5 times
faster).  The benchmarks for this optimized version are what is presented
below.


### Day 3 Benchmarks

```
>> Day 03a
benchmarking...
time                 315.9 μs   (305.7 μs .. 327.0 μs)
                     0.991 R²   (0.988 R² .. 0.996 R²)
mean                 312.0 μs   (303.6 μs .. 318.4 μs)
std dev              28.62 μs   (24.06 μs .. 34.34 μs)
variance introduced by outliers: 75% (severely inflated)

* parsing and formatting times excluded

>> Day 03b
benchmarking...
time                 1.430 ms   (1.355 ms .. 1.524 ms)
                     0.980 R²   (0.972 R² .. 0.990 R²)
mean                 1.503 ms   (1.467 ms .. 1.537 ms)
std dev              130.1 μs   (103.9 μs .. 153.7 μs)
variance introduced by outliers: 64% (severely inflated)

* parsing and formatting times excluded
```



Day 4
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day04.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d04p]* / *[Code][d04g]* / *[Rendered][d04h]* / *[Standalone Reflection Page][d04r]*

[d04p]: https://adventofcode.com/2020/day/4
[d04g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day04.hs
[d04h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day04.html
[d04r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day04.md

I almost hit the leaderboard today, but hit the 1 minute timeout because I
didn't read carefully enough to treat `cid` as optional ;\_;

Ah well, that's life!

Anyway, there are a lot of great Haskell solutions out there involving parser
combinators and validation of different fields, stuff like that.  My original
solution parsed a map of fields to values, and then validated those values
according to their keys.

But taking a step back from it all, I thought it would be a nice opportunity to
try out the principal of [Parse, Don't Validate][pdv] and see if I can take it
its extremes!  And implementing this in a nice way lead me also to refinement
types with the *[refined][]* library, and also and the [higher-kinded
data][hkd] pattern, supported by  the *[barbies][]* library.

[pdv]: https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/
[hkd]: https://reasonablypolymorphic.com/blog/higher-kinded-data/
[barbies]: https://hackage.haskell.org/package/barbies
[refined]: https://hackage.haskell.org/package/refined

So, what is "Parse, Don't Validate"?  It means: instead of parsing your data
into some structure and then checking if the structure is valid (like my
original parse-a-map-then-check-it), try instead to represent your data in a
structure where it is *imposssible* to represent or create an invalid instance
in the first place.  And so what was originally "validation" is now simply
parsing your data into that correct-by-construction structure.

This seemed like a good candidate for the *[refined][]* library, which gives us
data types that are "literally" impossible to construct unless they are in the
right shape.

```haskell
-- | (a <-> b) will represent the type of an integer between a and b
type a <-> b  = Refined (FromTo a b) Int
-- | (n ** a) will represent the type of a list of a's with exactly n elements
type n ** a   = Refined (SizeEqualTo n) [a]

-- | These come included in the library
refineThrow :: Int -> Maybe (a <-> b)
refineThrow :: [a] -> Maybe (n ** a)
```

Which gives us a good picture for the type of our "correct-by-construction"
passport:

```haskell
data Height =
    HCm (150 <-> 193)
  | HIn ( 59 <->  76)

data Eye = AMB | BLU | BRN | GRY | GRN | HZL | OTH

data Passport = Passport
    { pByr :: 1920 <-> 2002
    , pIyr :: 2010 <-> 2020
    , pEyr :: 2020 <-> 2030
    , pHgt :: Height
    , pHcl :: 6 ** (0 <-> 15)
    , pEcl :: Eye
    , pPid :: 9 ** (0 <-> 9)
    }
```

Et voila!  We now have a passport where it is impossible to construct unless
you have all the correct components!

That's great and all, but...how do we actually parse our data type into this?

One way that could work is to parse each key-value pair into a `Passport` with
all fields blank except for the field corresponding to that key-value pair, and
then combining those optional-field passports into a "certain" passport.

So we can imagine:

```haskell
data PassportMaybe = PassportMaybe
    { pByrMaybe :: Maybe (1920 <-> 2002)
    , pIyrMaybe :: Maybe (2010 <-> 2020)
    , pEyrMaybe :: Maybe (2020 <-> 2030)
    , pHgtMaybe :: Maybe Height
    , pHclMaybe :: Maybe (6 ** (0 <-> 15))
    , pEclMaybe :: Maybe Eye
    , pPidMaybe :: Maybe (9 ** (0 <-> 9))
    }
```

with an appropriate `Monoid` instance that merges known fields together, and a
function like

```haskell
fromPassportMaybe :: PassportMaybe -> Maybe Passport
```

that will only work if all the fields are `Just`.

And hey, we would also maybe like to keep a collection of all the parsers so we
can dispatch them whenever we want...

```haskell
data PassportParser = PassportParser
    { pByrParser :: String -> Maybe (1920 <-> 2002)
    , pIyrParser :: String -> Maybe (2010 <-> 2020)
    , pEyrParser :: String -> Maybe (2020 <-> 2030)
    , pHgtParser :: String -> Maybe Height
    , pHclParser :: String -> Maybe (6 ** (0 <-> 15))
    , pEclParser :: String -> Maybe Eye
    , pPidParser :: String -> Maybe (9 ** (0 <-> 9))
    }
```

And wait a minute ... doesn't part 1 require us to create a passport *without*
validating the strings?  So we also need to create

```haskell
data PassportRaw = PassportRaw
    { pByrRaw :: String
    , pIyrRaw :: String
    , pEyrRaw :: String
    , pHgtRaw :: String
    , pHclRaw :: String
    , pEclRaw :: String
    , pPidRaw :: String
    }
```

And also

```haskell
data PassportRawMaybe = PassportRawMaybe
    { pByrRaw :: Maybe String
    , pIyrRaw :: Maybe String
    , pEyrRaw :: Maybe String
    , pHgtRaw :: Maybe String
    , pHclRaw :: Maybe String
    , pEclRaw :: Maybe String
    , pPidRaw :: Maybe String
    }
```

as well, for the accumulation part?  Wow, this sounds like a horrible idea!

Or...does it?  What if we try the old [higher-kinded data][hkd] trick?

```haskell
data Passport f = Passport
    { pByr :: f (1920 <-> 2002)
    , pIyr :: f (2010 <-> 2020)
    , pEyr :: f (2020 <-> 2030)
    , pHgt :: f Height
    , pHcl :: f (6 ** (0 <-> 15))
    , pEcl :: f Eye
    , pPid :: f (9 ** (0 <-> 9))
    }
  deriving (Generic)
```

Neat, huh?  We now have a flexible data type that can account for all usage
patterns!  For example:

```haskell
-- | the original
type FullPassport = Passport Identity

-- | the optional-field
type PassportMaybe = Passport Maybe

-- | the parser collection
newtype Parser a = Parser { runParser :: String -> Maybe a }
type PassportParser = Passport Parser

-- | the raw strings
newtype Const w a = Const { getConst :: w }
type PassportRaw = Passport (Const String)

 -- | the optional raw strings
type PassportRaw = Passport (Const (Maybe String))
```

We get all of our original desired types, all from a single type definition, by
swapping out the functor `f` we use!  And then we can just use the
*[barbies][]* library to convert between the different formats.  Neat!

Well, what are we waiting for?

First, let's derive all of the instances necessary for our parsing to work,
given by the *barbies* and *one-liner-instances* packages.

```haskell
instance FunctorB Passport
instance ApplicativeB Passport
instance TraversableB Passport
instance ConstraintsB Passport
deriving via GMonoid (Passport f) instance AllBF Semigroup f Passport => Semigroup (Passport f)
deriving via GMonoid (Passport f) instance AllBF Monoid f Passport => Monoid (Passport f)
deriving instance AllBF Show f Passport => Show (Passport f)
```

Now we can write our parsers:

```haskell
newtype Parser a = Parser { runParser :: String -> Maybe a }

passportParser :: Passport Parser
passportParser = Passport
    { pByr = Parser $ refineThrow <=< readMaybe
    , pIyr = Parser $ refineThrow <=< readMaybe
    , pEyr = Parser $ refineThrow <=< readMaybe
    , pHgt = Parser $ \str ->
                let (x, u) = span isDigit str
                in  case u of
                      "cm" -> fmap HCm . refineThrow =<< readMaybe x
                      "in" -> fmap HIn . refineThrow =<< readMaybe x
                      _    -> Nothing
    , pHcl = Parser $ \case
                '#':n -> refineThrow =<< traverse readHex n
                _     -> Nothing
    , pEcl = Parser $ readMaybe . map toUpper
    , pPid = Parser $ refineThrow <=< traverse (refineThrow <=< readMaybe . (:[]))
    }
  where
    readHex c
      | isHexDigit c = refineThrow (digitToInt c)
      | otherwise    = Nothing
```

The usage of `refineThrow` means that we use the machinery already defined in
the *[refined][]* library to automatically check that our data is within the
given ranges...no need for manual range checking!

Now we can load a single `key:val` token into a passport that is *empty* (all
fields are `Const Nothing`) *except for* the value at the seen key

```haskell
-- | Load a single "key:val" token into a passport
loadPassportField :: String -> Passport (Const (Maybe String))
loadPassportField str = case splitOn ":" str of
    [k,v] -> case k of
      "byr" -> mempty { pByr = Const (Just v) }
      "iyr" -> mempty { pIyr = Const (Just v) }
      "eyr" -> mempty { pEyr = Const (Just v) }
      "hgt" -> mempty { pHgt = Const (Just v) }
      "hcl" -> mempty { pHcl = Const (Just v) }
      "ecl" -> mempty { pEcl = Const (Just v) }
      "pid" -> mempty { pPid = Const (Just v) }
      _     -> mempty
    _     -> mempty
```

```haskell
ghci> loadPassportField "eyr:1234"
Passport
  { pByr = Const Nothing
  , pIyr = Const Nothing
  , pEyr = Const (Just "1234")
  , pHgt = Const Nothing
  , pHcl = Const Nothing
  , pEcl = Const Nothing
  , pPid = Const Nothing
  }
```

Now we can parse a field in its entirety by using `bzipWith` (from *barbies*),
to "zip together" a `Passport Parser` and `Passport (Const (Maybe String))`
with a given function that tells how to merge the values in any two fields.

```haskell
parsePassportField :: String -> Passport Maybe
parsePassportField = bzipWith go passportParser . loadPassportField
  where
    go p (Const x) = runParser p =<< x
```

In the above, `go` is run between each matching field in the `Passport Parser`
and the `Passport (Const (Maybe String))`, and the overall effect is that each
string is run with the appropriate parser for its field.

```haskell
ghci> parsePassportField "eyr:2025"
Passport
  { pByr = Nothing
  , pIyr = Nothing
  , pEyr = Just (refined 2025)
  , pHgt = Nothing
  , pHcl = Nothing
  , pEcl = Nothing
  , pPid = Nothing
  }
ghci> parsePassportField "eyr:2050"
Passport
  { pByr = Nothing
  , pIyr = Nothing
  , pEyr = Nothing
  , pHgt = Nothing
  , pHcl = Nothing
  , pEcl = Nothing
  , pPid = Nothing
  }
```

And the way the `Monoid` instance works, we can just combine two `Passport
Maybe`s with `<>`:

```haskell
ghci> parsePassportField "eyr:2025" <> parsePassportField "ecl:brn"
Passport
  { pByr = Nothing
  , pIyr = Nothing
  , pEyr = Just (refined 2025)
  , pHgt = Nothing
  , pHcl = Nothing
  , pEcl = Just BRN
  , pPid = Nothing
  }
```

Which gives us a nice function to parse a whole passport, with the help of
`btraverse` to flip a `Passport Maybe` into a `Maybe (Passport Identity)`

```haskell
parsePassport :: String -> Maybe (Passport Identity)
parsePassport = btraverse (fmap Identity)
              . foldMap parsePassportField
              . words
```

The result of `foldMap parsePassportField . words` is a `Passport Maybe`, and
`btraverse` "pulls out" all of the `Just` fields and returns a `Passport
Identity` if all of the fields are `Just`, failing with `Nothing` if any of the
fields are `Nothing`.

And...that's it for part 2!

```haskell
-- | Get a list of all valid passports.
part2 :: String -> [Passport Identity]
part2 = mapMaybe parsePassport . splitOn "\n\n"
```

This works because we know that if we have a `Passport Identity`, we *know* it
has to be a valid passport.  It's physically impossible to create one that
isn't valid!

**All hail "Parse, Don't Validate"!**

And part 1 is a fun diversion: instead of a `Passport Identity`, we want to
parse into a `Passport (Const String)` instead.  The mechanics are pretty much
the same:

```haskell
loadPassport :: String -> Maybe (Passport (Const String))
loadPassport = btraverse (\(Const x) -> Const <$> x)
             . foldMap loadPassportField
             . words
```

The result of `foldMap loadPassportField` is a `Passport (Const (Maybe
String))`, and so `btraverse` will pull out all the `Just`s again, returning a
`Passport (Const String)` and failing if any of those values were `Nothing`s.
Note the sliiight abuse of the `Monoid` instance for `Maybe`, which combines
strings by concatenation.  But we're more concerned about whether or not it is
present than the actual contents of the string.

Anyway, here's wonderwall.

```haskell
-- | Get a list of all complete passports field string values.
part1 :: String -> [Passport (Const String)]
part1 = mapMaybe loadPassport . splitOn "\n\n"
```


### Day 4 Benchmarks

```
>> Day 04a
benchmarking...
time                 1.527 ms   (1.415 ms .. 1.655 ms)
                     0.969 R²   (0.954 R² .. 0.988 R²)
mean                 1.662 ms   (1.604 ms .. 1.702 ms)
std dev              176.0 μs   (133.5 μs .. 265.1 μs)
variance introduced by outliers: 73% (severely inflated)

* parsing and formatting times excluded

>> Day 04b
benchmarking...
time                 4.856 ms   (4.611 ms .. 5.008 ms)
                     0.971 R²   (0.946 R² .. 0.986 R²)
mean                 4.897 ms   (4.720 ms .. 5.123 ms)
std dev              611.3 μs   (427.5 μs .. 857.6 μs)
variance introduced by outliers: 72% (severely inflated)

* parsing and formatting times excluded
```



Day 5
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day05.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d05p]* / *[Code][d05g]* / *[Rendered][d05h]* / *[Standalone Reflection Page][d05r]*

[d05p]: https://adventofcode.com/2020/day/5
[d05g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day05.hs
[d05h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day05.html
[d05r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day05.md

So, compared to yesterday's, this was decently chill :)

The main insight here probably is that the puzzle is just describing that the
seat ID's are straight up binary notation for numerals, with F/L representing
what is traditionally 0, and B/R representing what is traditionally 1.  So we
can use any of our binary parsers from the standard libraries, or we can just
directly pull it into binary.

```haskell
seatId :: String -> Int
seatId = foldl' iGuessWe'reDoingThis 0
  where
    iGuessWe'reDoingThis n = \case
      'B' -> 2*n+1
      'R' -> 2*n+1
      _   -> 2*n
```

A nice one-pass way to find the missing seat ID is to realize that if we sum
all the numbers from min to max, and sum all of our lists's seat id's, then the
difference is the missing number.  Luckily there's a nice closed-form solution
for the sum of all numbers in a given range (the sum of numbers from `a` to `b`
is ``b*(b+1)`div`2 - a*(a-1)`div`2``), so we can do all of this in a single
pass using the *[foldl][]* library

[foldl]: https://hackage.haskell.org/package/foldl

```haskell
{-# LANGUAGE ApplicativeDo #-}
import qualified Control.Foldl as F

findHole :: F.Fold Int (Maybe Int)
findHole = do
    mn <- F.minimum
    mx <- F.maximum
    sm <- F.sum
    pure $
      missingItem <$> mn <*> mx <*> pure sm
  where
    missingItem mn mx sm = totalSum - sm
      where
        totalSum = mx*(mx+1)`div`2 - mn*(mn-1)`div`2
```

A `F.Fold Int (Maybe Int)` folds a list of `Int`s into a `Maybe Int`.  You can
run it with `F.fold :: F.Fold a b -> [a] -> b`.

I really like the *foldl* library because it lets you build a complex
single-pass fold by combining multiple simple single-pass folds (like
`F.minimum`, `F.maximum`, `F.sum`) using an Applicative interface.  We need to
do a bit of wrangling with the `Maybe`s because `F.minimum` and `F.maximum`
each return `Maybe Int`.

And that's more or less it!  We can actually represent the entire thing as a
fold if we use `F.premap`, to pre-map a fold...


```haskell
F.premap                 :: (c -> a) -> F.Fold a b -> F.Fold c b

-- "pre-apply" `setId` so we fold over a string instead
F.premap seatId findHole :: F.Fold String (Maybe Int)
```

And...that's enough to do it all in a single pass!

```haskell
part1 :: [String] -> Maybe Int
part1 = F.fold $ F.premap seatId F.maximum

part2 :: [String] -> Maybe Int
part2 = F.fold $ F.premap seatId findHole
```

Bonus: I was tipped off that the 3rd from last digit of F/L are 1, while the
same digit of B/R are 0:

```haskell
ghci> (.&. 1) . (`shiftR` 2) . ord <$> "FLBR"
[1,1,0,0]
```

So we can actually use this for `seatId` to get a slight speed boost and help
out the branch predictor maybe:

```haskell
import Data.Bits

seatId :: String -> Int
seatId = foldl' iGuessWe'reDoingThis 0
  where
    iGuessWe'reDoingThis n c =
      2 * n + (complement (ord c) `shiftR` 2) .&. 1
```


### Day 5 Benchmarks

```
>> Day 05a
benchmarking...
time                 17.82 μs   (17.80 μs .. 17.83 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 17.85 μs   (17.83 μs .. 17.90 μs)
std dev              99.61 ns   (62.10 ns .. 135.5 ns)

* parsing and formatting times excluded

>> Day 05b
benchmarking...
time                 18.71 μs   (18.70 μs .. 18.72 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 18.70 μs   (18.70 μs .. 18.71 μs)
std dev              29.62 ns   (22.55 ns .. 42.77 ns)

* parsing and formatting times excluded
```



Day 6
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day06.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d06p]* / *[Code][d06g]* / *[Rendered][d06h]* / *[Standalone Reflection Page][d06r]*

[d06p]: https://adventofcode.com/2020/day/6
[d06g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day06.hs
[d06h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day06.html
[d06r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day06.md

Another day that is fairly straightforward in Haskell, I feel!  But in other
languages that support functional approaches, it should be straightforward as
well.

The answer involves lists of groups of responses:

```haskell
import           Data.List.NonEmpty
import           Data.Set
import qualified Data.List.NonEmpty as NE
import qualified Data.Set           as S

type Response = Set Char
type Group    = NonEmpty Response

parseAnswers :: Set Char -> [Group]
parseAnswers = mapMaybe ((fmap . fmap) S.fromList . NE.nonEmpty . lines)
             . splitOn "\n\n"
```

And now we just need to decide how to aggregate each group.  For part 1, this
requires a set union between every `Response` in a `Group`:

```haskell
part1 :: [Group] -> Int
part1 = sum . map (S.size . foldr1 S.union)
```

(`foldr1` here is safe because we have a non-empty container)

And for part 2, this requires a set intersection between every `Response` in a
`Group`:


```haskell
part2 :: [Group] -> Int
part2 = sum . map (S.size . foldr1 S.intersection)
```

That's it!


### Day 6 Benchmarks

```
>> Day 06a
benchmarking...
time                 143.3 μs   (135.9 μs .. 148.1 μs)
                     0.986 R²   (0.979 R² .. 0.993 R²)
mean                 148.7 μs   (145.5 μs .. 152.0 μs)
std dev              13.11 μs   (10.75 μs .. 17.27 μs)
variance introduced by outliers: 76% (severely inflated)

* parsing and formatting times excluded

>> Day 06b
benchmarking...
time                 151.2 μs   (145.6 μs .. 157.2 μs)
                     0.981 R²   (0.962 R² .. 0.994 R²)
mean                 178.9 μs   (157.5 μs .. 231.7 μs)
std dev              119.8 μs   (56.72 μs .. 202.3 μs)
variance introduced by outliers: 99% (severely inflated)

* parsing and formatting times excluded
```



Day 7
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day07.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d07p]* / *[Code][d07g]* / *[Rendered][d07h]* / *[Standalone Reflection Page][d07r]*

[d07p]: https://adventofcode.com/2020/day/7
[d07g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day07.hs
[d07h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day07.html
[d07r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day07.md

Another AoC staple, a graph search that can be solved with recursive knot
tying!  The last one I remember off the top of my head was [2019 Day
6][2019d06].

[2019d06]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-6

Here we can represent a graph as a map of vertices to other vertices, with an
edge value:

```haskell
type Graph v e = Map v (Map v e)
```

Exercise is left to the reader to parse our dataset into a `Graph String Int`,
a graph of bags to bags with `Int` edges.

Because our map has no cycles, we can take advantage of recursive knot tying to
"fold up" all children and sub-children.

For example, part 1 can be written as:

```haskell
allDescendants :: Ord v => Graph v e -> Map v (Set v)
allDescendants gr = descendantMap
  where
    descendantMap = gr <&>
      M.foldMapWithKey (\v _ -> S.insert v (M.findWithDefault S.empty v descendantMap))

-- note: (<&>) is flip fmap
```

Here we "assume" we already have a fully-featured `Map v (Set v)` map of
vertices to all their descendants, and then build `descendantMap` in terms of
it.  For every vertex `v` in the `Map v e` directly underneath a given vertex,
`v` is a descendant, and also all of `v`'s descendants (which we find by
looking things up in `descendantMap`, the map of all descendants).

Oh, um...oops, this found all the descendants, but we want all of the
ancestors.  So we have to flip the graph if we want to use this.

```haskell
flipGraph :: Ord v => Graph v e -> Graph v e
flipGraph mp = M.fromListWith M.union
    [ (m, M.singleton n e)
    | (n, ms) <- M.toList mp
    , (m, e ) <- M.toList ms
    ]

allAncestors :: Ord v => Graph v e -> Map v (Set v)
allAncestors = allDescendants . flipGraph
```

And so that leaves Part 1 as:

```haskell
part1 :: Graph String (String Int) -> Maybe (Set String)
part1 = M.lookup "shiny gold" . allAncestors
```

Part 2 we can do a similar way, by "assuming" we have a map of all vertices to
their "usage count", and looking things up to build it:

```haskell
usageCounts :: Ord v => Graph v Int -> Map v Int
usageCounts gr = usageMap
  where
    usageMap = gr <&> \neighbors -> sum
      [ n * (M.findWithDefault 0 v usageMap + 1)
      | (v, n) <- M.toList neighbors
      ]
```

So to find the total usage of each bag, we look under each `(v, Int)` pair in the
`Map v Int` underneath a given vertex, look up the usage of that `v` (by
looking it up in `usageMap`), add 1 (because the bag itself is used), and
multiply by `n`, the number of times the full contents of the bag is used.

And so Part 2 is:

```haskell
part2 :: Graph String (String Int) -> Maybe Int
part2 = M.lookup "shiny gold" . usageCounts
```

If we stare at the two implementations, we note that both are pretty much the
same overall structure: we are accumulating some sort of fold over all
descendants of a given node.  If we "outsource" this accumulation as a monoidal
one (for part 1, it's `Set` union, and for part 2, it's `Sum Int` addition), we
can needlessly hyper-generalize this to fold over any `Monoid` instance.

```haskell
-- | Recursively fold up a monoid value for each vertex and all of its
-- children's monoid values.  You can transform the value in-transit before it
-- is accumulated if you want.
foldMapGraph
    :: (Ord v, Monoid m)
    => (v -> m)         -- ^ embed the vertex
    -> (e -> m -> m)    -- ^ transform with edge before it is accumulated
    -> Graph v e
    -> Map v m
foldMapGraph f g gr = res
  where
    res = gr <&>
      M.foldMapWithKey (\s v -> f s <> foldMap (g v) (M.lookup s res))

allDescendants :: Ord v => Graph v e -> Map v (Set v)
allDescendants = foldMapGraph
    S.singleton     -- the node is embedded as itself
    (\_ -> id)      -- ignore the edge

usageCounts :: Ord v => Graph v Int -> Map v (Sum Int)
usageCounts = foldMapGraph
    (const 0)                   -- ignore the nodes
    (\n x -> Sum n * (x + 1))   -- the edge multiplies the accumulator plus one
```

That's the curse of Haskell, I guess?  If you write these things you can't help
but notice the common patterns, and you somehow wind up trying to figure out
the higher-order function that can abstract over them, even though you know you
don't need to :)


### Day 7 Benchmarks

```
>> Day 07a
benchmarking...
time                 1.703 ms   (1.676 ms .. 1.738 ms)
                     0.997 R²   (0.995 R² .. 0.999 R²)
mean                 1.685 ms   (1.667 ms .. 1.702 ms)
std dev              67.82 μs   (57.66 μs .. 85.26 μs)
variance introduced by outliers: 27% (moderately inflated)

* parsing and formatting times excluded

>> Day 07b
benchmarking...
time                 14.68 μs   (14.26 μs .. 14.98 μs)
                     0.996 R²   (0.994 R² .. 0.999 R²)
mean                 14.71 μs   (14.48 μs .. 14.99 μs)
std dev              889.5 ns   (579.7 ns .. 1.397 μs)
variance introduced by outliers: 68% (severely inflated)

* parsing and formatting times excluded
```



Day 8
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day08.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d08p]* / *[Code][d08g]* / *[Rendered][d08h]* / *[Standalone Reflection Page][d08r]*

[d08p]: https://adventofcode.com/2020/day/8
[d08g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day08.hs
[d08h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day08.html
[d08r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day08.md

Nothing tooooo complicated about today's, I feel: it is another staple of
AoC --- simulating a virtual machine! :)  Only this time our program is
separate from our memory, so we don't have any actual self-modifying code.
However, my guard is up: this might turn into one of those soon in another day.

At least, there are some interesting things we can do to prepare for a
potential switch to different requirements in a later day (with the `Ixed`)
typeclass, and also a nice way to handle the perturbations in Part 2 using
`holesOf` and lens traversal composition.

My main program was a sequence of `Command`:

```haskell
data Instr = NOP | ACC | JMP

type Command = (Instr, Int)
```

But, what container should we use for these?

1.  `[Command]`: Nope, bad, literally no reason to ever use this except for
    O(1) push and pop.  The main operation here is indexing, and it's O(i) on
    the index.
2.  `Vector Command`: Very fast indexing (O(1) on the index), but very bad for
    any sort of addition of new instructions in-flight if that comes up in the
    future.  But good enough for now.
3.  `Seq Command`: Efficient indexing (O(1) on the index), and very good for
    adding new instructions to either end (or even in the middle) in-flight if
    it comes to that.
4.  `IntMap Command`: Efficient indexing (O(1) on the index), very good for
    adding new instructions to either end, and also good for a sparse program
    bank if it ever comes to that.

*Luckily*, we can get a common interface for all four of these options by using
the `Ixed` typeclass from the *lens* library, which abstracts over different
"indexable" things.  You'd get a safe index with `xs ^? ix i`.  So whenever
possible, I've written all my code to work generally over all four of these in
case I have to swap quickly in the future.

One theoretical nice container would actually be the `PointedList` data type
(one implementation is in the *[pointedlist][]* library).  This is because all
of our addressing is relative, so instead of storing a "current index", we
could just always point towards the focus of the tape, and shift the tape left
or right for `JMP`.

[pointedlist]: https://hackage.haskell.org/package/pointedlist-0.6.1/docs/Data-List-PointedList.html

However, this is kind of difficult to adapt to work in a uniform interface to
the other four types...so, goodbye theoretical nicety, sacrificed in the name
of adaptivity :'(

So for my solution I used `Vector`, which has just the API necessary without
the extra flexibility that `Seq` and `IntMap` offer, since we don't need it!
But, just know that things could be swapped at any time, thanks to the magic
(or horror, depending on your point of view) of typeclasses.

On the other hand, if we separate out the index from a fixed container, it does
make the state a lot simpler.  It means that our state is really only the
current pointer and the accumulator:

```haskell
data CState = CS { csPtr :: !Int, csAcc :: !Int }

initialCS :: CState
initialCS = CS 0 0

runCommand :: Vector Command -> CState -> Maybe CState
```

So our actual program becomes a very tight `CState -> Maybe CState` loop --
very efficient because the state is only a tuple!  That means that we can
simply chain things using `iterateMaybe` go get a list of all successive
states:

```haskell
-- | A handy utility function I keep around
iterateMaybe :: (a -> Maybe a) -> a -> [a]
iterateMaybe f = go
  where
    go x = x : case f x of
      Nothing -> []
      Just y  -> go y

allStates :: Vector Command -> [CState]
allStates cmd = iterateMaybe (runCommand cmd) initialCS
```

So now we have a generator of all the states a given program bank will ever
output.  For part 1, we just need to find a loop.  Luckily I have another handy
utility function that scans a list and reports the first time a projection
function's result is repeated

```haskell
-- | Lazily find the first repeated projection.
firstRepeatedBy :: Ord a => (b -> a) -> [b] -> Maybe b
firstRepeatedBy f = go S.empty
  where
    go seen (x:xs)
      | f x `S.member` seen = Just x
      | otherwise           = go (f x `S.insert` seen) xs
    go _ []     = Nothing

part1 :: Vector Command -> Maybe CState
part1 cmd = firstRepititionBy csPtr states
  where
    states = iterateMaybe (runCommand cmd) inititialCS
```

Now all that's left is to actually implement `runCommand`!

```haskell
runCommand
    :: Vector Command
    -> CState
    -> Maybe CState
runCommand cmds cs = (cmds ^? ix (csPtr cs)) <&> \case
    (NOP, _) -> cs { csPtr = csPtr cs + 1 }
    (ACC, i) -> cs { csPtr = csPtr cs + 1, csAcc = csAcc cs + i }
    (JMP, i) -> cs { csPtr = csPtr cs + i }

-- note: <&> is flip fmap
```

And the nice thing about it is that if we leave off the type annotation of
`runCommand`, we actually get a really nice polymorphic type if we ask GHC what
it expects:

```haskell
runCommand
    :: (Ixed t, Index t ~ Int, IxValue t ~ (Instr, Int))
    => t
    -> CState
    -> Maybe CState
```

This is the fully polymorphic signature that you get just from using `cmds ^?
ix (csPtr cs)`.  It says that you can use this on *any* program bank `t` that's
an instance of `Ixed`, as long as its index type is `Int` and the value at that
index is a `(Instr, Int)`.  Nothing about the typeclasses here is inherently
lensy, it's just a typeclass (like any other) to abstract over common
interfaces that many types might have.  In this fully polymorphic signature, we
can use this on `Vector Command`, `[Command]`, `Seq Command`, and `IntMap
Command`, as we wish to in the future if the need comes up.

For part 2 we can take advantage of some *actual* lens/optics magic, by using
`holesOf`:

```haskell
holesOf
    :: Traversal' s a
    -> s
    -> [Pretext (->) a a s]
```

The type is definitely scary, but `holesOf` is saying:

1.  Give me a specification of which holes you want to poke (`Traversal' s a`,
    a value `s` with holes `a`)
2.  ... and an item you want to poke the holes in (`s`)
3.  ... and I'll return to you a list of continuations (`Pretext (->) a a (t
    a)`), each one allowing you to edit a different hole in `s`.

`Pretext` is a bit of a complicated type, but the main interface you would use
it with is:

```haskell
peeks :: (a -> a) -> Pretext (->) a a s -> s
```

`peeks` as for a function you would want to run on a hole (the `a -> a`), the
continuation you got from `holesOf`, and then returns the "modified" `s`,
modified according to that transformation you ran on that hole.

(thanks to *mniip* on freenode IRC for pointing out how these two work together
to me!)

Every item in the list returned by `holesOf` corresponds to a different hole,
so for example:

```haskell
ghci> map (peeks negate) (holesOf traverse [1,2,3])
  [ [-1, 2, 3]
  , [ 1,-2, 3]
  , [ 1, 2,-3]
  ]
```

The `traverse :: Traversal' [a] a` is a `Traversal` that specifies the "holes"
of a list `[a]` to be each item `a` in that list.  And so `holesOf traverse
[1,2,3]` will return three `Pretext`s: one corresponding to modifying each item
in the list individually.

`peeks negate` on each of the three items returned by `holesOf traverse
[1,2,3]` will return the modified list, each with a single hole edited by
`negate`.

In our case, instead of `negate`, we can use a `flipInstr` that flips `NOP` to
`JMP` and `JMP` to `NOP`:

```haskell
flipInstr :: Command -> Command
flipInstr = \case
    NOP -> JMP
    ACC -> ACC
    JMP -> NOP
```

And now `peeks flipInstr` will do the right thing:

```haskell
ghci> map (peeks flipInstr) (holesOf traverse [NOP,ACC,JMP,JMP])
[ [JMP,ACC,JMP,JMP]
, [NOP,ACC,JMP,JMP]
, [NOP,ACC,NOP,JMP]
, [NOP,ACC,JMP,NOP]
]
```

An extra coolio thing is that traversals compose with `.`, so we can actually
use a traversal `_1` (here, `Traversal' (a,b) a`, which says the single "hole"
in an `(a,b)` is the first item in the tuple) to be more nuanced with our hole
selection:

```haskell
ghci> map (peeks flipInstr)
        (holesOf (traverse . _1) [(NOP,1),(ACC,2),(JMP,3),(JMP,4)])
  [ [(JMP,1),(ACC,2),(JMP,3),(JMP,4)]
  , [(NOP,1),(ACC,2),(JMP,3),(JMP,4)]
  , [(NOP,1),(ACC,2),(NOP,3),(JMP,4)]
  , [(NOP,1),(ACC,2),(JMP,3),(NOP,4)]
  ]
```

Neat!

With that we can fully write `part2`: for each perturbation, check if there is
a loop.  If there is a loop, this ain't it.  If there isn't a loop, then we hit
the jackpot: return the last item in our list of seen states, as that's the
last state before termination.

```haskell
part2 :: Vector Command -> Maybe CState
part2 cmds0 = listToMaybe
    [ res
    | cmds <- peeks flipInstr <$> holesOf (traverse . _1) cmds0
    , let states = iterateMaybe (runCommand cmds) initialCS
    , res  <- case firstRepeatedBy csPtr stats of
        Nothing -> [last states]    -- loop found
        Just _  -> []               -- no loop found
    ]
```

In my actual code, I actually use the `experiment` function instead of `peeks`
-- it's like a "peeksM", in a way:

```haskell
peeks      :: (a ->   a) -> Pretext (->) a a s ->   a
experiment :: (a -> f a) -> Pretext (->) a a s -> f a
```

So instead of giving it a `Instr -> Instr`, you could give it an `Instr ->
Maybe Instr`, and "cancel out" any branches that don't need to be addressed:

```haskell
experiment :: (a -> Maybe a) -> Pretext (->) a a s -> Maybe a   -- in our case

flipInstrs :: Command -> Maybe Command
flipInstrs = \case
    NOP -> Just JMP
    ACC -> Nothing  -- for ACC indices, don't do anything
    JMP -> Just JMP
```

```haskell
ghci> map (experiment flipInstrs)
        (holesOf (traverse . _1) [(NOP,1),(ACC,2),(JMP,3),(JMP,4)])
[ Just [(JMP,1),(ACC,2),(JMP,3),(JMP,4)]
, Nothing
, Just [(NOP,1),(ACC,2),(NOP,3),(JMP,4)]
, Just [(NOP,1),(ACC,2),(JMP,3),(NOP,4)]
]
```

```haskell
part2 :: Vector Command -> Maybe CState
part2 cmds0 = listToMaybe
    [ res
    | Just cmds <- experiment flipInstr <$> holesOf (traverse . _1) cmds0
    , let states = iterateMaybe (runCommand cmds) initialCS
    , res  <- case firstRepeatedBy csPtr stats of
        Nothing -> [last states]    -- loop found
        Just _  -> []               -- no loop found
    ]
```

Not a super huge improvement, but maybe more theoretically nice because we can
skip over the possible trials where we are permuting an `ACC`.  By my
reckoning, 52% of my input file instructions were ACC instructions, so this
small thing actually shaves off a decent amount of time.


### Day 8 Benchmarks

```
>> Day 08a
benchmarking...
time                 8.055 μs   (7.625 μs .. 8.507 μs)
                     0.988 R²   (0.978 R² .. 0.996 R²)
mean                 8.153 μs   (7.856 μs .. 8.438 μs)
std dev              848.3 ns   (634.4 ns .. 1.081 μs)
variance introduced by outliers: 88% (severely inflated)

* parsing and formatting times excluded

>> Day 08b
benchmarking...
time                 2.550 ms   (2.475 ms .. 2.637 ms)
                     0.991 R²   (0.987 R² .. 0.995 R²)
mean                 2.541 ms   (2.504 ms .. 2.571 ms)
std dev              125.0 μs   (101.9 μs .. 156.3 μs)
variance introduced by outliers: 33% (moderately inflated)

* parsing and formatting times excluded
```



Day 9
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day09.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d09p]* / *[Code][d09g]* / *[Rendered][d09h]* / *[Standalone Reflection Page][d09r]*

[d09p]: https://adventofcode.com/2020/day/9
[d09g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day09.hs
[d09h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day09.html
[d09r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day09.md

Let's tackle day 9!

A good way to check if a sequence of 25 numbers can add to the 26th number is
to just iterate over everything, like we might have done in day 1:

```haskell
-- | check if, for ([x,y,z] ++ [a]), no pair in xyz can add to 'a'.  If it's
-- bad, it returns 'Just a'.
isBad :: [Int] -> Maybe Int
isBad xs0 = do
    x : xs <- Just $ reverse xs0
    let badCheck = null do
          y:ys <- tails (toList xs)
          z    <- ys
          guard $ (y + z) == x
    x <$ guard badCheck
```

I use my favorite `Maybe` do-notation trick of pattern matching within the
block to take advantage of do block short circuiting for `Maybe` with its
`MonadFail` instance.  If you reverse `xs0` then you can get the last item as
the head, and the rest as the tail :)

In `badCheck` we do a list-monad powered search (see my [Day 1
Reflections](https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day01.md))
for more details on how it works.  `badCheck` will return `True` if the search
is empty (with `null`).  `guard badCheck` will be Nothing if `badCheck` fails
(and our list is good) and `Just x` if `badCheck` succeeds (and our list is
bad).

Part 1 is then just finding the first bad sequence:

```haskell
part1 :: [Int] -> Maybe Int
part1 xs = listToMaybe
    [ y
    | ys     <- tails xs
    , Just y <- [isBad (take 26 ys)]
    ]
```

For part 2, there's a nice-ish way to do it in constant-time.  First, we can
generate a cumulative sum `cumSum` for the *entire* list.  Then we know that
`sumFrom(i,j)` in our original list is just `cumSum(j) - cumSum(i)`.  This is
similar to how definite integrals work, or also how you can find the area under
a probability density function by subtracting two points from its cumulative
distribution function.

So now the problem just becomes finding `i,j` where `cumSum(j) - cumSum(i) ==
goal`.  There's a clean imperative-ish way to do this that involves just
"sliding" your window `i,j` up from `0,1`.  If `cumSum(j) - cumSum(i)` is too
small, increase `j` by 1 to open the window up a bit.  If it's too big,
increase `i` by 1 to close the window up a bit.

```haskell
findBounds :: V.Vector Int -> Int -> Maybe (Int, Int)
findBounds ns goal = go 0 1
  where
    go !i !j = do
      x <- ns V.!? i
      y <- ns V.!? j
      case compare (y - x) goal of
        LT -> go i (j + 1)
        EQ -> pure (i, j)
        GT -> go (i + 1) j
```

And there you go!

```haskell
part2 :: [Int] -> Maybe Int
part2 xs = do
    goal <- part1 xs
    let cumSum = V.fromList (scanl' (+) 0 xs)       -- cumulative sum
    (i, j) <- findBounds cumSum goal
    let xs = take (j - i) . drop i $ ns
    pure $ minimum xs + maximum xs
```

If anything, maybe the implementation of `findBounds` shows how one might
directly translate a tight mutable loop in an imperative language into a
tail-recursive function in Haskell!

We do often like to avoid explicitly writing recursive functions when we can,
but in this case I'm not sure if there's a way to get around it other than
switching to a full on mutable answer, or in a very complex way that is
extremely specific to the situation.  If you think of one, let me know! :D


### Day 9 Benchmarks

```
>> Day 09a
benchmarking...
time                 164.4 μs   (154.6 μs .. 179.6 μs)
                     0.973 R²   (0.965 R² .. 0.984 R²)
mean                 178.5 μs   (170.9 μs .. 184.6 μs)
std dev              22.16 μs   (19.45 μs .. 24.65 μs)
variance introduced by outliers: 86% (severely inflated)

* parsing and formatting times excluded

>> Day 09b
benchmarking...
time                 215.2 μs   (208.9 μs .. 219.5 μs)
                     0.987 R²   (0.977 R² .. 0.995 R²)
mean                 214.1 μs   (207.6 μs .. 224.2 μs)
std dev              28.57 μs   (19.93 μs .. 40.26 μs)
variance introduced by outliers: 87% (severely inflated)

* parsing and formatting times excluded
```



Day 10
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day10.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d10p]* / *[Code][d10g]* / *[Rendered][d10h]* / *[Standalone Reflection Page][d10r]*

[d10p]: https://adventofcode.com/2020/day/10
[d10g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day10.hs
[d10h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day10.html
[d10r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day10.md

Today is another day where the "automatically build a memoized recursive map"
in Haskell really shines :)  It's essentially the same problem as Day 7.

For the first part, once you sort the list, you can compute the differences and
then build a frequency map

```haskell
-- | Build a frequency map
freqs :: Ord a => [a] -> Map a Int
freqs = M.fromListWith (+) . map (,1) . toList

diffs :: [Int] -> [Int]
diffs xs@(_:ys) = zipWith (-) ys xs
```

```haskell
ghci> diffs [1,3,4,7]
[2,1,3]
```

And so part 1 can be done with:

```haskell
part1 :: [Int] -> Int
part1 xs = (stepFreqs M.! 1) * (stepFreqs M.! 3)
  where
    xs' = 0 : xs ++ [maximum xs + 3]
    stepFreqs = freqs (diffs (sort xs'))
```


For part 2, if we get an `IntSet` of all of your numbers (and adding the zero,
and the goal, the maximum + 3), then we can use it to build our `IntMap` of all
the number of paths from a given number.

```haskell
import           Data.IntMap (IntMap)
import           Data.IntSet (IntSet)
import qualified Data.IntMap as IM
import qualified Data.IntSet as IS

-- | A map of numbers to the count of how many paths from that number to
-- the goal
pathsToGoal :: IntSet -> IntMap Int
pathsToGoal xs = res
  where
    res = flip IM.fromSet xs $ \i ->
      if i == goal
        then 1
        else sum [ IM.findWithDefault 0 (i + j) res
                 | j <- [1,2,3]
                 ]
    goal = IS.findMax is
```

Our answer is `res`, the map of numbers to the count of how many paths exist
from that number to the goal.  To generate the count for a given number `i`, we
add the number of paths from `i+1`, `i+2`, and `i+3`.  We get that count by
looking it up in `res`!

```haskell
part2 :: [Int] -> Int
part2 xs = pathsToGoal xs IM.! 0
  where
    xs' = IS.fromList (0 : xs ++ [maximum xs + 3])
```

A quick note --- after some discussion on the irc, we did [find a closed-form
solution][d10cfs]...I might be editing this to implement it in Haskell
eventually :)

[d10cfs]: https://www.reddit.com/r/adventofcode/comments/kabi91/2020_day_10_closedform_mathematical_solution/


### Day 10 Benchmarks

```
>> Day 10a
benchmarking...
time                 7.446 μs   (6.857 μs .. 8.049 μs)
                     0.965 R²   (0.953 R² .. 0.980 R²)
mean                 7.693 μs   (7.232 μs .. 8.045 μs)
std dev              1.281 μs   (1.111 μs .. 1.404 μs)
variance introduced by outliers: 95% (severely inflated)

* parsing and formatting times excluded

>> Day 10b
benchmarking...
time                 9.980 μs   (9.898 μs .. 10.08 μs)
                     0.999 R²   (0.999 R² .. 1.000 R²)
mean                 10.00 μs   (9.953 μs .. 10.10 μs)
std dev              216.9 ns   (138.4 ns .. 328.4 ns)
variance introduced by outliers: 22% (moderately inflated)

* parsing and formatting times excluded
```



Day 11
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day11.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d11p]* / *[Code][d11g]* / *[Rendered][d11h]* / *[Standalone Reflection Page][d11r]*

[d11p]: https://adventofcode.com/2020/day/11
[d11g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day11.hs
[d11h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day11.html
[d11r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day11.md

My first day on the leaderboard! :D  21 / 352.  Had a big dip on my second part
because I had some silly typos that were difficult to catch in the moment D:

After refactoring things, I realized that part 1 and part 2 are really the
same, with only two differences:

1.  Each point as a different neighborhood set (in part 1, it's the immediate
    neighbors; in part 2, it's all of the line-of-sights in each direction).
2.  Threshold for seats unseating is 4 for part 1 and 5 for part 2.

So let's write our function parameterized on those two.  We'll be storing our
world as a `Map Point Bool`, where `False` represents an empty seat and `True`
represents a full one.  Floor points are not included in the map.

```haskell
-- | A 2-vector type from the linear library, with a very convenient Num
-- instance.
data V2 a = V2 a a

type Point = V2 Int

-- | A useful utility function I keep around that counts the number of items in
-- a container matching a predicate
countTrue :: Foldable f => (a -> Bool) -> f a -> Int
countTrue p = length . filter p . toList

seatRule
    :: Int                       -- ^ exit seat threshold
    -> Map Point (Set Point)     -- ^ neighbors for each point
    -> Map Point Bool
    -> Map Point Bool
seatRule thr nmp mp = M.intersectionWith go nmp mp
  where
    go neighbs = \case
      Empty -> not (all (mp M.!) neighbs)
      Full  ->
        let onNeighbs = countTrue (mp M.!) neighbs
        in  not (onNeighbs >= thr)
```

Now we just need to create our neighborhood maps.

```haskell
-- | The eight immediate neighbors around 0,0
immediateNeighbs :: [Point]
immediateNeighbs =
    [ V2 dx dy
    | dx <- [-1 .. 1]
    , dy <- if dx == 0 then [-1,1] else [-1..1]
    ]

-- | From a set of seat locations, get a map of points to all of those points'
-- neighbors where there is a seat. Should only need to be computed once.
lineOfSights1
    :: Set Point
    -> Map Set (Set Point)
lineOfSeights1 pts = M.fromSet go mp
  where
    go p _ = S.fromList
           . filter (`S.member` pts)
           . (+ p)
           $ immediateNeighbs

-- | From a set of seat locations, Get a map of points to all of those points'
-- visible neighbors. Should only need to be computed once.
lineOfSights2
    :: Set Point
    -> Map Point (Set Point)
lineOfSights2 bb pts = M.mapWithKey go pts
  where
    go p _ = S.fromList
           . mapMaybe (los p)
           $ immediateNeighbs
    los p d = find (`S.member` pts)
            . takeWhile inBoundingBox
            . tail
            $ iterate (+ d) p
    inBoundingBox = all (inRange (0, 99))
        -- inRange from Data.Ix
        -- all from Data.Foldable and V2's Foldable instance
```

(I hard-coded the bounds here, but in my actual solution I inferred it from the
input.)

Now to solve!

```haskell
-- | Handy utility function I have; repeat a function until you get the same
-- result twice.
fixedPoint :: Eq a => (a -> a) -> a -> a
fixedPoint f = go
  where
    go !x
        | x == y    = x
        | otherwise = go y
      where
        y = f x

solveWith
    :: Int                      -- ^ exit seat threshold
    -> Map Point (Set Point)    -- ^ neighbors for each point
    -> Map Point Bool           -- ^ initial state
    -> Int                      -- ^ equilibrium size
solveWith thr neighbs = countTrue id . fixedPoint (seatRule thr neighbs)

part1
    :: Map Point Bool
    -> Int
part1 mp = solveWith 4 los mp
  where
    los = lineOfSight1 (M.keysSet mp)

part2
    :: Map Point Bool
    -> Int
part2 mp = solveWith 5 los mp
  where
    los = lineOfSight2 (M.keysSet mp)
```


### Day 11 Benchmarks

```
>> Day 11a
benchmarking...
time                 131.5 ms   (126.6 ms .. 138.6 ms)
                     0.996 R²   (0.988 R² .. 1.000 R²)
mean                 135.8 ms   (133.3 ms .. 139.1 ms)
std dev              4.926 ms   (3.075 ms .. 7.107 ms)
variance introduced by outliers: 11% (moderately inflated)

* parsing and formatting times excluded

>> Day 11b
benchmarking...
time                 136.4 ms   (129.4 ms .. 142.6 ms)
                     0.998 R²   (0.995 R² .. 1.000 R²)
mean                 137.5 ms   (134.5 ms .. 141.0 ms)
std dev              5.265 ms   (3.297 ms .. 7.107 ms)
variance introduced by outliers: 11% (moderately inflated)

* parsing and formatting times excluded
```



Day 12
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day12.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d12p]* / *[Code][d12g]* / *[Rendered][d12h]* / *[Standalone Reflection Page][d12r]*

[d12p]: https://adventofcode.com/2020/day/12
[d12g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day12.hs
[d12h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day12.html
[d12r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day12.md

Hello!  Today's puzzle for me ended up a neat exercise in fitting together
simple parts into something fun.

To preface this, I do usually represent all my coordinates using `V2 Int` from
the *[linear](https://hackage.haskell.org/package/linear)* library, which
supports addition and scaling:

```haskell
data V2 a = V2 !a !a

type Point = V2 Int

-- | You can add points using the Num instance
(+) :: Point -> Point -> Point

-- | You can do scaling
(*^) :: Int -> Point -> Point
```

And I have a utility type that represents a compass direction:

```haskell
data Dir = North | East | South | West

dirPoint :: Dir -> Point
dirPoint = \case
    North -> V2   0   1
    East  -> V2   1   0
    South -> V2   0 (-1)
    West  -> V2 (-1)  0

rotPoint :: Num a => Dir -> V2 a -> V2 a
rotPoint = \case
    North -> id
    East  -> \(V2 x y) -> V2   y  (-x)
    West  -> \(V2 x y) -> V2 (-y)   x
    South -> negate
```

And I do like to define a `Group` interface for my `Dir` type, just for fun.

```haskell
-- | If you consider a Dir as a turn, then `mulDir a b` is like turning a, then
-- turning b.
mulDir :: Dir -> Dir -> Dir
mulDir North = id
mulDir East  = \case North -> East
                     East  -> South
                     South -> West
                     West  -> North
mulDir South = \case North -> South
                     East  -> West
                     South -> North
                     West  -> East
mulDir West  = \case North -> West
                     East  -> North
                     South -> East
                     West  -> South

-- | '<>' is 'mulDir'.
instance Semigroup Dir where
    (<>) = mulDir

-- | If you consider Dir as a turn, then turning by North is the same as not
-- turning at all.
instance Monoid Dir where
    mempty = North

-- | Reverse a turn.  Not needed for this puzzle, but still useful in general.
instance Group Dir where
    invert = \case North -> South
                   East  -> West
                   South -> North
                   West  -> East
```

I did not write any of this for the puzzle --- this is just a nice way I like
to think about directions and points in my head :)

One major advantage of defining a `Semigroup` instance for `Dir` is that you can
take advantage of the `pow` function from
[Data.Group](https://hackage.haskell.org/package/groups-0.5.2/docs/Data-Group.html):

```haskell
pow :: Group m => m -> Int -> m
```

which is like `stimes`, but supporting negative numbers.  `pow x 3` is `x <> x
<> x`, and `pow x (-3)` is `invert x <> invert x <> invert x`, or `invert (x <>
x <> x)` (same thing, 'cause Group theory).  We don't actually need the support
for negative numbers in this puzzle, so we could just use `stimes`, but it's
nice that we can just use `pow` and not think about our input range.  And,
though it doesn't matter for this challenge, it also uses [repeated
squaring](https://en.wikipedia.org/wiki/Exponentiation_by_squaring) so it can
do these operations in log-n time (`pow x 1000000000` only takes 30
operations), which is pretty neat for a lot of different applications (like [in
my writeup for 2019 Day
22](https://blog.jle.im/entry/shuffling-things-up.html)).

Anyway I think that's enough preamble...now let's use it! :D  Each instruction
seems to be one of three forms: "go forward", "turn", or "move an absolute
vector".  So I represented these three as a data type, parameterized by the
amount to go forward, the direction to turn, and the vector to move by,
respectively.

And each first character gives us a different way to process the `Int`
argument, so I stored those instructions in a `Map`.  Then we can parse it by
just using `readMaybe :: Read a => String -> Maybe a` on a pattern match.

```haskell
data Instr = Forward Int
           | Turn Dir
           | Move Point
  deriving Show

-- | A map of a Char to the way to interpret the Int argument
mkInstr :: Map Char (Int -> Instr)
mkInstr = M.fromList
    [ ('F', Forward)
    , ('L', Turn . pow West . (`div` 90))
    , ('R', Turn . pow East . (`div` 90))
    , ('N', Move . (*^ dirPoint North))
    , ('S', Move . (*^ dirPoint South))
    , ('E', Move . (*^ dirPoint East ))
    , ('W', Move . (*^ dirPoint West ))
    ]

parseInstr :: String -> Maybe Instr
parseInstr []    = Nothing
parseInstr (c:n) = M.lookup c mkInstr <*> readMaybe n
```

```haskell
ghci> parseInstr "F30"
Forward 30
ghci> parseInstr "L270"
Turn East
ghci> parseInstr "N15"
Move (V2 0 15)
```

And now part 1, part 2 are basically just different ways of folding through a
list of instructions:

```haskell
toInstrs :: String -> [Instr]
toInstrs = traverse parseInstr . lines

-- | Use (ship heading, position) as the state
part1 :: [Instr] -> (Dir, Point)
part1 = foldl' go (East, V2 0 0)
  where
    go :: (Dir, Point) -> Instr -> (Dir, Point)
    go (!dir, !p) = \case
      Forward n -> (dir     , p + n *^ dirPoint dir)
      Turn d    -> (dir <> d, p                    )
      Move r    -> (dir     , p + r                )

-- | Use (ship position, waypoint vector from ship) as the state
part2 :: [Instr] -> (Point, Point)
part2 = foldl' go (V2 0 0, V2 10 1)
  where
    go :: (Point, Point) -> Instr -> (Point, Point)
    go (!shp, !wp) = \case
      Forward n -> (shp + n *^ wp, wp           )
      Turn d    -> (shp          , rotPoint d wp)
      Move r    -> (shp          , wp + r       )
```

And that's it!  For `part1`, we want the mannhattan distance of the ship's
final position (the second item in the tuple), and for part2, we want the
manhattan distance of the ship's final position (the first item in the tuple).

```haskell
mannDist :: Point -> Int
mannDist (V2 x y) = abs x + abs y
````


### Day 12 Benchmarks

```
>> Day 12a
benchmarking...
time                 3.561 μs   (3.512 μs .. 3.619 μs)
                     0.998 R²   (0.998 R² .. 0.999 R²)
mean                 3.604 μs   (3.571 μs .. 3.631 μs)
std dev              111.7 ns   (95.06 ns .. 130.5 ns)
variance introduced by outliers: 40% (moderately inflated)

* parsing and formatting times excluded

>> Day 12b
benchmarking...
time                 10.26 μs   (9.800 μs .. 10.94 μs)
                     0.984 R²   (0.976 R² .. 0.995 R²)
mean                 10.55 μs   (10.22 μs .. 10.87 μs)
std dev              1.077 μs   (784.8 ns .. 1.359 μs)
variance introduced by outliers: 86% (severely inflated)

* parsing and formatting times excluded
```



Day 13
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day13.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d13p]* / *[Code][d13g]* / *[Rendered][d13h]* / *[Standalone Reflection Page][d13r]*

[d13p]: https://adventofcode.com/2020/day/13
[d13g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day13.hs
[d13h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day13.html
[d13r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day13.md

Aw man, I feel like I would have leaderboarded today had I not been busy :'(
These type of number theory problems are the ones I usually do well on.

Oh well!  Silly internet points, right?

For part 1, you just need to minimize a function on each bus ID:

```haskell
part1 :: Int -> [Int] -> (Int, Int)
part1 t0 xs = minimumBy (comparing snd)
    [ (x, waitTime)
    | x <- xs
    , let waitTime = x - (t0 `mod` x)
    ]
```

Part 2 is where things get interesting!  Let's try to think of things
inductively: start with small lists, and see how we would "add one more".

Let's say we had `(offset, id)` pairs `(0,7)` and `(1,13)`, like in the
example.  This means that we want to find times where ``t `mod` 7 == 0`` and
``(t + 1) `mod` 13 == 0``.

We can sort of do a manual search by hand to get `14` as our lowest candidate.
But also, note that `14 + (7*13)n` for any integer `n` would preserve the offset
property.  `14`, `14 + 91`, `14 + 182`, etc.  So the family of all "valid"
numbers are `14 + (7*13)n`.

Next, what if we wanted to find the situation for pairs `(0,7)`, `(1,13)`, and
`(4,15)`?  Well, we already know that any solution that includes `(0,7)` and
`(1,13)` will be of the form `14 + (7*13)n`.  So now we just need to find the
*first* one of those that also matches `(4,15)`

```haskell
-- 'until' repeatedly applies a function until it finds a value that matches a
-- predicate
ghci> until (\t -> (t + 4) `mod` 15 == 0) (+ (7*13)) 14
1106
```

Ah hah, good ol' `1106`.  Well, `1106` isn't the only number that works.
We can see that `1106 + (7*13*15)n` for any integer n would *also* work, since
it preserves that mod property.

And so, we can repeat this process over and over again for each new number we
see.

1.  Keep track of the current "lowest match" (`14`) and the current "search
    step" (`7*13`).
2.  When you see a number, search that family until you find a new lowest match
    that includes the new number.
3.  Use that new number as the next lowest match, and multiply it to get the
    new search step.
4.  Rinse and repeat.

Overall, this works pretty well as a `foldl`, where we keep this `(lowest
match, search step)` pair as an accumulator, and update it as we see each new
value in our list.

```haskell
part2 :: [(Int, Int)] -> Int
part2 = fst . foldl' go (0, 1)
  where
    go (!base, !step) (offset, i) = (base', step * i)
      where
        base' = iterateFind (\n -> (n + offset) `mod` i == 0)
                            (+ step)
                            base
```


### Day 13 Benchmarks

```
>> Day 13a
benchmarking...
time                 248.4 ns   (237.3 ns .. 255.2 ns)
                     0.986 R²   (0.977 R² .. 0.992 R²)
mean                 233.9 ns   (222.3 ns .. 242.7 ns)
std dev              32.93 ns   (28.64 ns .. 37.78 ns)
variance introduced by outliers: 95% (severely inflated)

* parsing and formatting times excluded

>> Day 13b
benchmarking...
time                 3.811 μs   (3.805 μs .. 3.816 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 3.795 μs   (3.790 μs .. 3.799 μs)
std dev              15.85 ns   (13.59 ns .. 18.67 ns)

* parsing and formatting times excluded
```



Day 14
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day14.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d14p]* / *[Code][d14g]* / *[Rendered][d14h]* / *[Standalone Reflection Page][d14r]*

[d14p]: https://adventofcode.com/2020/day/14
[d14g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day14.hs
[d14h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day14.html
[d14r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day14.md

I guess today is a "here's the algorithm, now implement it" puzzle, to
contrast/take a break from yesterday's "here's the goal, figure out the
algorithm" :)

First, let's start with an intermediate data type representing the actions
possible on each line:

```haskell
data Instr =
      Mask [Maybe Bool]
    | Write Int Int
```

The mask will be a list of `Maybe Bool`, where `X` is `Nothing`, `0` is `Just
False`, and `1` is `Just True`.  However, it's important to reverse the string
when parsing it from the input, because we want index `0` to correspond to bit
`0`, index `1` to correspond to bit `1`, etc., to make our lives easier.

That's because we can implement the application of a mask (for part 1) using
[`ifoldl'`](https://hackage.haskell.org/package/lens-4.19.2/docs/Control-Lens-Indexed.html#v:ifoldl-39-),
a version of `foldl'` that gives you an item's index as you are folding it:

```haskell
import           Data.Bits (clearBit, setBit)
import           Control.Lens.Indexed (ifoldl')

applyMask1 :: Int -> [Maybe Bool] -> Int
applyMask1 = ifoldl' $ \i x -> \case
    Nothing    -> x
    Just False -> clearBit x i
    Just True  -> setBit   x i
```

If the bit list contains a `Nothing` in a given index, leave the item
unchanged.  If it contains a `Just False`, clear that index's bit (set it to
zero).  If it contains a `Just Nothing`, set that index's bit (set it to one).

And that leaves part 1 as a foldl through all the instructions, keeping the
current map and mask as state:

```haskell
import           Data.IntMap (IntMap)
import qualified Data.IntMap as IM

part1 :: [Instr] -> (IntMap Int, [Maybe Bool])
part1 = foldl' go (IM.empty, [])
  where
    go :: (IntMap Int, [Maybe Bool]) -> Instr -> (IntMap Int, [Maybe Bool])
    go (!mp, !msk) = \case
      Mask  msk'   -> (mp, msk')
      Write addr n ->
        let mp' = IM.insert addr (applyMask1 n msk) mp
        in  (mp', msk)
```

Part 2's mask application is interesting, because it lives in
"non-determinancy".  Basically, each bit mask bit application could potentially
yield multiple possibilities.  We have to accumulate every nested possibility.
This feature is given to us by list's `Monad` instance, so we can swap
`ifoldl'` for
[`ifoldM`](https://hackage.haskell.org/package/lens-4.19.2/docs/Control-Lens-Indexed.html#v:ifoldlM):

```haskell
ifoldl' :: (Int -> b -> a ->   b) -> b -> [a] ->   b
ifoldlM :: (Int -> b -> a -> m b) -> b -> [a] -> m b
```

For `ifoldlM`, each result lives in monad `m`, so the semantics of "proceeding
along the fold" are deferred to the `Monad` instance for `m`.  If `m` is
`Maybe`, it means that you only proceed if you get a `Just`, or else
short-circuit with `Nothing`.  If `m` is `IO`, it means that proceeding
involves chaining the IO action's execution and binding the result to give it
to the function's next iteration.  If `m` is `[]` (list), it means that
subsequent chaining will run the function on every *possibility* returned by
the function's previous call, accumulating every possible way of choosing every
possible choice. (I talked about this in more depth in [one of my first ever
Haskell blog
posts](https://blog.jle.im/entries/series/+monadplus-success-failure-monads.html)).

```haskell
import           Control.Lens.Indexed (ifoldlM)

applyMask2 :: Int -> [Maybe Bool] -> [Int]
applyMask2 = ifoldlM $ \i x -> \case
    Nothing    -> [clearBit x i, setBit x i]
    Just False -> [x]
    Just True  -> [setBit x i]
```

For these, we return a list of every possible change from a given bit mask bit.
For the `Nothing` "floating" case, there are two possibilities; for the other
two, there is only one.  We trust list's `Monad` instance to properly thread
over all possible results into a list of all possible changes that that `Int`
could have been subjected to.

And so, part 2 looks a lot like part 1!

```haskell
part2 :: [Instr] -> (IntMap Int, [Maybe Bool])
part2 = foldl' go (IM.empty, [])
  where
    go :: (IntMap Int, [Maybe Bool]) -> Instr -> (IntMap Int, [Maybe Bool])
    go (!mp, !msk) = \case
      Mask  msk'   -> (mp, msk')
      Write addr n ->
        let newMp = IM.fromList ((,n) <$> applyMask2 addr msk)
        in  (newMp <> mp, msk)
```

`(<>)` here is a left-biased merger, so it merges in all of the newly seen
indices into the existing ones.


### Day 14 Benchmarks

```
>> Day 14a
benchmarking...
time                 164.4 μs   (163.7 μs .. 165.3 μs)
                     0.999 R²   (0.999 R² .. 1.000 R²)
mean                 160.4 μs   (158.9 μs .. 162.0 μs)
std dev              5.716 μs   (4.989 μs .. 6.870 μs)
variance introduced by outliers: 33% (moderately inflated)

* parsing and formatting times excluded

>> Day 14b
benchmarking...
time                 29.89 ms   (26.80 ms .. 33.08 ms)
                     0.959 R²   (0.885 R² .. 0.995 R²)
mean                 30.44 ms   (29.25 ms .. 32.87 ms)
std dev              3.399 ms   (1.949 ms .. 5.879 ms)
variance introduced by outliers: 45% (moderately inflated)

* parsing and formatting times excluded
```



Day 15
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day15.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d15p]* / *[Code][d15g]* / *[Rendered][d15h]* / *[Standalone Reflection Page][d15r]*

[d15p]: https://adventofcode.com/2020/day/15
[d15g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day15.hs
[d15h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day15.html
[d15r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day15.md

So it is yet another "here's the algorithm, implement it" days again!  Only the
challenge this time is...you should probably implement it to be really fast!

I don't think there is *too* much wiggle room in how to implement things here;
my original solution basically kept an `IntMap` to the last seen time of any
value, and just repeatedly looked things up and modified the (current time,
last said) tuple.

My original solution took around 70 seconds to run, and that was what I used to
submit things originally.  But let's see if we can get it down to something a
little less...perceptible :)  This reflection can be a deep dive into writing
tight, performant Haskell.

The data type we'll be using is an *[unboxed mutable
array](https://hackage.haskell.org/package/vector/docs/Data-Vector-Unboxed-Mutable.html)*.
There's a trick we can use because we have a map from integers to values, we
can just use the integer keys as the index to an array.  This is usually a bad
idea but for the fact that the keys we'll be using are bounded within a
decently small range (we won't ever say a number that is greater than 30
million), so we can definitely accumulate 30 million-item array into memory
without any major problems.  We'll also store our last-said times as `Int32` to
be a little bit more efficient since we're trying to eek out every last bit of
perf.

So overall we still keep some state: the current time and the last said item.
Since those are just integers, we can keep that as pure in memory using
`StateT` running over `ST s` (the mutable state monad, where our mutable
vectors will live).

```haskell
import           Control.Monad.ST
import           Control.Monad.State
import           GHC.Int (Int32)
import qualified Data.Vector.Unboxed.Mutable as MV

data LoopState = LS
    { lsLastSaid :: !Int
    , lsCurrTime :: !Int32
    }

sayNext
    :: MV.MVector s Int32                   -- ^ the mutable vector of last-seen times
    -> StateT (T2 Int32 Int) (ST s) ()      -- ^ an 'ST s' action with some pure (T2 Int32 Int) state
sayNext v = do
    L s i <- get                        -- get the current pure state
    lst <- MV.read v x                  -- our last said is x, so look up the last time we saw it
    MV.write v x i                      -- update the last-time-seen
    let j | lst == 0  = 0               -- we haven't seen it
          | otherwise = i - lst         -- we have seen it
    put (LS (fromIntegral j) (i + 1))   -- update last seen and current time
{-# INLINE sayNext #-}
```

We will want to INLINE this so that it gets inlined directly into our main loop
code.

Oh, let's also write a function to initialize our sequence with starting
inputs:

```haskell
saySomething
    :: MV.MVector s Int32                   -- ^ the mutable vector of last-seen times
    -> Int                                  -- ^ a number to "say"
    -> StateT (T2 Int32 Int) (ST s) ()      -- ^ an 'ST s' action with some pure (T2 Int32 Int) state
saySomething v y = do
    LS x i <- get
    MV.unsafeWrite v x i          -- write the last seen number with the right time
    put (LS y (i + 1))            -- queue up the write of the number to say
{-# INLINE saySomething #-}
```

And now we're good to go to put it all together!  We can use `whileM_` from
*[Control.Monad.Loops](https://hackage.haskell.org/package/monad-loops/docs/Control-Monad-Loops.html)*
to emulate a while loop, where our condition is whenever `lsCurrTime` reaches
the maximum value.

```haskell
-- | Returns 'True' until we need to stop
stopCond :: Int32 -> StateT (T2 Int32 Int) m Bool
stopCond n = gets $ \(LS _ i) -> i < n
{-# INLINE stopCond #-}
-- gets f = f <$> get, it maps a function on top of a get

looper :: Int -> [Int] -> Int
looper n xs = runST $ flip evalStateT (LS 0 0) $ do
    v <- MV.replicate n 0       -- initialize our vector with zeros
    traverse_ (saySomething v) xs
    whileM_ (stopCond n) (sayNext v)
    gets lsLastSaid
```

On my machine (with some minor optimizations, like using
`unsafeRead`/`unsafeWrite`), this runs in 230ms for part 2...a much more
reasonable improvement over my original 70 seconds! :)

```haskell
part1 :: [Int] -> Int
part1 = looper 2020

part2 :: [Int] -> Int
part2 = looper 30000000
```


### Day 15 Benchmarks

```
>> Day 15a
benchmarking...
time                 2.770 μs   (2.721 μs .. 2.819 μs)
                     0.993 R²   (0.987 R² .. 0.997 R²)
mean                 2.804 μs   (2.731 μs .. 2.980 μs)
std dev              410.5 ns   (218.1 ns .. 710.5 ns)
variance introduced by outliers: 94% (severely inflated)

* parsing and formatting times excluded

>> Day 15b
benchmarking...
time                 227.2 ms   (221.4 ms .. 232.6 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 231.2 ms   (228.0 ms .. 239.5 ms)
std dev              6.796 ms   (587.6 μs .. 9.527 ms)
variance introduced by outliers: 14% (moderately inflated)

* parsing and formatting times excluded
```



Day 16
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day16.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d16p]* / *[Code][d16g]* / *[Rendered][d16h]* / *[Standalone Reflection Page][d16r]*

[d16p]: https://adventofcode.com/2020/day/16
[d16g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day16.hs
[d16h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day16.html
[d16r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day16.md

Today was a nice little self-contained constraint satisfaction problem!  Well,
it didn't have to be (apparently), but it was fun as one :)

First, our data type:

```haskell
type Passport = [Int]

data Info = Info
      { iFields :: IntervalMap Int (Set Text)
      , iYours  :: Passport
      , iTheirs :: [Passport]
      }
```

Here we're using `IntervalMap` from the *[data-interval][]* package, which
makes it easy to store data at different intervals with easy lookups.  For
example, if we have `["class"]` at interval `(1,5)`, and we had `["row"]` at
interval `(3,7)`, `IntervalMap` will merge them together (with `<>`, if we
choose) to get `["class"]` at `(1,3)`, `["class","row"]` at `(3,5)`, and
`["row"]` at `(5,7)`.

[data-interval]: https://hackage.haskell.org/package/data-interval

If we have this `IntervalMap`, part 1 becomes straightforward enough with the
efficient `IM.notMember`:

```haskell
import qualified Data.IntervalMap.Lazy as IM

part1 :: Info -> Int
part1 info = sum
    [ n
    | ns <- iTheirs info
    , n  <- ns
    , n `IM.notMember` iFields info
    ]
```

So now let's move on to the search for part 2!

Our goal is to get a list `[(Int, Set Text)]` of a column number (in the
passport) with the set of all valid field names for that position.  And because
we are going to be doing a search, we want this list in order of smallest to
largest valid-name sets.

First, we can replace the `Int`s in each passport instead with the set of
fields they are valid for

```haskell
validate :: IntervalMap Int (Set Text) -> [Int] -> Maybe [Set Text]
validate flds = traverse (`IM.lookup` flds)

validateAll :: IntervalMap Int (Set Text) -> [Passport] -> [[Set Text]]
validateAll flds = mapMaybe (validate flds)
```

Here ``(`IM.lookup` flds)`` is `Int -> Set Text`: it'll look up the `Set Text`
corresponding to the interval that the `Int` falls under in the `IntervalMap`.
It'll return `Nothing` if *any* of the `Int`s are invalid, and `Just` if *all*
of the `Int`s are valid.

Next we want to build our `[(Int, Set Text)]`.  The `Set Text` is a set of what
is valid for that column number, so to get the `Set Text` for `0`, for
instance, we need to `S.intersection` all of the first `Set Text`s in our list,;
to get the `Set Text` for `1`, we need to `S.intersection` all of the second
`Set Text`s in our lists, etc.  This can be done succinctly with a `transpose`
(`transpose [[1,2,3],[4,5,6]] == [[1,4],[2,5],[3,6]]`).  Then we can use
`sortOn` to sort by the size of the valids set.

```haskell
columnSets :: [[Set Text]] -> [(Int, Set Text)]
columnSets = sortOn (S.size . snd)
           . zip [0..]
           . map (foldl1' S.intersection)
           . transpose
```

Now we're ready for our search!  We'll be using `StateT` over list, to get a
backtracking search with backtracking state (I described this technique in [a
constraint solving blog
post](https://blog.jle.im/entry/unique-sample-drawing-searches-with-list-and-statet.html)).
Our state will be the `Set Text` of all the "committed" fields so far.

```haskell
search :: [(Int, Set Text)] -> Maybe [(Int, Text)]
search candidateMap = listToMaybe . flip evalStateT S.empty $ do
    for candidates $ \(i, cands) -> do              -- for each (Int, Set Text):
      soFar <- get                                  -- get the seen candidates
      pick  <- lift . toList $ cands S.\\ soFar     -- pick from the Set Text not including seens
      (i, pick) <$ modify (S.insert pick)           -- propose this index/pick, inserting into seens
```

And that should be it for our search!  In the end this gets the first `[(Int,
Text)]` that is valid, matching a column ID to the field at that column.  Our
search supports backtracking through the list monad, but it should be noted
that we actually don't end up needing it for the way the puzzle input is
structured.  But, because we sort our lists first from smallest to largest
valid-sets, our solution ends up being equivalent to the non-backtracking
method and backtracking is never actually triggered.

And we can wrap it all up:

```haskell
part2 :: Info -> Int
part2 = product
    [ iYours info !! i
    | (i, fld) <- res
    , "departure" `isPrefixOf` fld
    ]
  where
    cSets    = columnSets $ validateAll (iFields info) (iTheirs info)
    Just res = search cSets
```


### Day 16 Benchmarks

```
>> Day 16a
benchmarking...
time                 821.6 μs   (817.5 μs .. 826.3 μs)
                     0.999 R²   (0.999 R² .. 1.000 R²)
mean                 813.7 μs   (806.6 μs .. 821.2 μs)
std dev              22.69 μs   (16.70 μs .. 29.36 μs)
variance introduced by outliers: 18% (moderately inflated)

* parsing and formatting times excluded

>> Day 16b
benchmarking...
time                 886.2 μs   (875.7 μs .. 905.0 μs)
                     0.997 R²   (0.992 R² .. 1.000 R²)
mean                 894.0 μs   (887.9 μs .. 906.7 μs)
std dev              30.87 μs   (19.73 μs .. 54.15 μs)
variance introduced by outliers: 25% (moderately inflated)

* parsing and formatting times excluded
```



Day 17
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day17.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d17p]* / *[Code][d17g]* / *[Rendered][d17h]* / *[Standalone Reflection Page][d17r]*

[d17p]: https://adventofcode.com/2020/day/17
[d17g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day17.hs
[d17h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day17.html
[d17r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day17.md

Neat, Game of Life! :D  Actually, the 3D/4D twist does make a big impact for
the best method we'd pick: we run into the [curse of
dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality).  It
means that when we get to 3D and 4D, our world will become vanishingly sparse.
In my own input, only about 4% of the 3D space ended up being active, and 2% of
my 4D space ends up being active.  This means that holding a dense vector of
all possible active points (which will be `(6+8+6)^n`) is up to 98% wasteful.
And because of the way this process works, we have to completely copy our
entire space at every iteration.

In these times, I'm happy that Haskell has a nice immutable sparse
data structure like `Set`.  Sparse being beneficial in that we can easily look up and process
only the 2% of active squares, and immutable being beneficial in that each step
already requires a full copy in any case, so immutability doesn't give us any
drawback.

First a function to get all neighbors of a point, using the `V3` type from the
*[linear](https://hackage.haskell.org/package/linear)* library, which I've used
many times already for its convenient `Num` and `Applicative` instances:

```haskell
import           Data.Set (Set)
import qualified Data.Set as S

-- from linear
data V3 a = V3 a a a
-- its Applicative instance
pure x = V3 x x x

neighbsSet :: V3 Int -> Set (V3 Int)
neighbsSet p = S.fromList
    [ p + d
    | d <- sequence (pure [-1,0,1])
    , d /= pure 0
    ]
```

Just as a reminder, `pure [0,1]` for `V3 Int` gives us `V3 [0,1] [0,1] [0,1]`,
and if we `sequence` that we get a cartesian N-product of all combinations `[V3
0 0, V3 0 0 1, V3 0 1 0, V3 0 1 1, V3 1 0 0, .. etc.]`.  We add each of those
to `p`, except for the one that is `V3 0 0 0`.

Now we can write our stepper, which takes a `Set (V3 Int)` and returns the next
`Set (V3 Int)` after applying the rules.  We can do that first by making a `Map
(V3 Int) Int`, where `Int` is the number of neighbors at a given point.  This
can be done by "exploding" every `V3 Int` in our set to a `Map (V3 Int) Int`,
a map of all its neighbors keyed to values 1, and then using `M.unionsWith (+)`
to union together all of those exploded neighbors, adding any overlapping keys.

```haskell
import           Data.Map (Map)
import qualified Data.Map as M

neighborMap :: Set (V3 Int) -> Map (V3 Int) Int
neighborMap ps = M.unionsWith (+)
    [ M.fromSet (const 1) (neighbsSet p)
    | p <- S.toList ps
    ]
```

Now to implement the rules:

```haskell
stepper
    :: Set (V3 Int)
    -> Set (V3 Int)
stepper ps = stayAlive <> comeAlive
  where
    neighborCounts = neighborMap ps
    stayAlive = M.keysSet . M.filter (\n -> n == 2 || n == 3) $
                  neighborCounts `M.restrictKeys` ps
    comeAlive = M.keysSet . M.filter (== 3) $
                  neighborCounts `M.withoutKeys`  ps
```

`stayAlive` is all of the `neighborCounts` keys that correspond to already-alive
points (``neighborCounts `M.restrictKeys` ps``), but filtered to the counts
that are 2 or 3.  `comeAlive` is all of the `neighborCounts` keys that
correspond to dead points (``neighborCounts `M.withoutKeys` ps``), but filtered
to only counts that are exactly 3.  And our result is the set union of both of
those.


So our part 1 becomes:

```haskell
part1 :: Set (V3 Int) -> Int
part1 = S.size . (!! 6) . iterate stepper
```

And for part 2...notice that all of our code actually never does anything
*specific* to `V3`!  In fact, if we leave the type signatures of `neighbsSet`
and `neighborMap` and `stepper` off, GHC will actually suggest more general
type signatures for us.

```haskell
neighbsSet
    :: (Applicative f, Num a, Eq (f a), Traversable f)
    => V3 a -> Set (V3 a)

neighborMap
    :: (Applicative f, Num a, Ord (f a), Traversable f)
    => Set (f a)
    -> Map (f a) Int

stepper
    :: (Applicative f, Num a, Ord (f a), Traversable f)
    => Set (f a)
    -> Set (f a)
```

Neat!  This means that our code *already works* for any other fixed-sized
`Vector` type with a `Num` instance.  Like, say...`V4`, also from *linear*?

```haskell
-- also from the Linear library, with all the same instances
data V4 a = V4 a a a a

part1 :: Set (V3 Int) -> Int
part1 = S.size . (!! 6) . iterate stepper

part2 :: Set (V4 Int) -> Int
part2 = S.size . (!! 6) . iterate stepper
```

And that's it --- code that should work for both parts :)


### Day 17 Benchmarks

```
>> Day 17a
benchmarking...
time                 4.025 ms   (3.914 ms .. 4.168 ms)
                     0.989 R²   (0.976 R² .. 0.996 R²)
mean                 4.028 ms   (3.934 ms .. 4.153 ms)
std dev              338.7 μs   (256.8 μs .. 461.4 μs)
variance introduced by outliers: 54% (severely inflated)

* parsing and formatting times excluded

>> Day 17b
benchmarking...
time                 18.76 ms   (17.61 ms .. 20.33 ms)
                     0.968 R²   (0.936 R² .. 0.991 R²)
mean                 19.49 ms   (18.95 ms .. 20.16 ms)
std dev              1.440 ms   (1.108 ms .. 2.085 ms)
variance introduced by outliers: 31% (moderately inflated)

* parsing and formatting times excluded
```



Day 18
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day18.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d18p]* / *[Code][d18g]* / *[Rendered][d18h]* / *[Standalone Reflection Page][d18r]*

[d18p]: https://adventofcode.com/2020/day/18
[d18g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day18.hs
[d18h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day18.html
[d18r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day18.md

Let's parse with parser combinators!

The main way I have learned how to deal with these binary-operation parsers is
to separate out the stages into a "bottom" level containing only the leaves
(here, the int literals) and parentheses, and then build up layers of
precedence one-by-one from highest to lowest.  For the first part we only have
two layers, then, since we only have one level of precedence.

```haskell
{-# LANGUAGE OverloadedStrings #-}

import qualified Text.Megaparsec            as P
import qualified Text.Megaparsec.Char       as P
import qualified Text.Megaparsec.Char.Lexer as PP

type Parser = P.Parsec Void String

parseBottom1 :: Parser Int
parseBottom1 = P.choice
    [ PP.decimal
    , P.between "(" ")" parseTop1  -- use -XOverloadedStrings to get parsers that match strings
    ]

parseTop1 :: Parser Int
parseTop1 = do
    leftOfOp <- parseBottom1   -- parse the left hand side of a possible binary operator
    doNext acc
  where
    doNext acc = P.choice          -- once we parse a left hand side, pick from:
      [ do " * "                        -- either it's a *
           rightOfOp <- parseBottom1    --   ... so we parse the right hand side and multiply
           doNext (acc * rightOfOp)
      , do " + "                        -- or it's a +
           rightOfOp <- parseBottom1    --   ... so we parse the right hand side and add
           doNext (acc + rightOfOp)
      , pure acc                        -- otherwise that was it, no operator
      ]
```

Remember that `leftOfOp` could either come from a leaf literal number or from a
parenthesized equation.  In the end, we get an `Int`, representing whatever
number was on the left hand side of our operator.  Then we move into `doNext`,
which continually accumulates new operations after that first `leftOfOp` parse.

If we see a `*`, we parse the right hand side, fold that into our accumulator
and repeat until we hit a dead end and yield our accumulated value; same for
`+`.

So there's this sort of "cycle" that `parseTop` defers to `parseBottom` for its
underlying things "in between" the operators, but `parseBottom` loops back up
to `parseTop` to handle what is in the parentheses.

```haskell
part1 :: String -> Maybe Int
part1 = P.parseMaybe $
          sum <$> P.many parseTop1
```

The twist for part 2 is that now we have to have another layer of precedence,
so we split things out:

```haskell
parseBottom2 :: Parser Int
parseBottom2 = P.choice
    [ PP.decimal
    , P.between "(" ")" parseTop2
    ]

parseMiddle2 :: Parser Int
parseMiddle2 = do
    leftOfOp <- parseBottom2
    doNext leftOfOp
  where
    doNext acc = P.choice
      [ do " + "
           rightOfOp <- parseBottom2
           doNext (acc + rightOfOp)
      , pure acc
      ]

parseTop2 :: Parser Int
parseTop2 = do
    leftOfOp <- parseMiddle2
    doNext leftOfOp
  where
    doNext acc = P.choice
      [ do " * "
           rightOfOp <- parseMiddle2
           doNext (acc * rightOfOp)
      , pure acc
      ]
```

So the parser dependency again is kind of interesting: `parseTop2` is built up
of chained `parseMiddle2`s, which is built up of chained `parseBottom2`, which
could loop back up with `parseTop2` if detect parentheses.

```haskell
part2 :: String -> Maybe Int
part2 = P.parseMaybe $
          sum <$> (parseTop2 `P.sepBy` P.newline)
```

Note that this chaining and looping behavior can be abstracted out --- that's
essentially what I wrote in my [cleaned up solution][d18g].  But also the
*[Control.Monad.Combinators.Expr](https://hackage.haskell.org/package/parser-combinators-1.2.1/docs/Control-Monad-Combinators-Expr.html)*
module also abstracts over this pattern, letting you specify the "layers" you
want, and it'll generate the right parser for you with the correct weaving of
dependencies like I described here.  But still, I think it's fun to see how
these things end up looking like under the hood :)


### Day 18 Benchmarks

```
>> Day 18a
benchmarking...
time                 2.628 ms   (2.442 ms .. 2.867 ms)
                     0.968 R²   (0.952 R² .. 0.992 R²)
mean                 2.573 ms   (2.485 ms .. 2.671 ms)
std dev              315.6 μs   (188.3 μs .. 456.3 μs)
variance introduced by outliers: 76% (severely inflated)

* parsing and formatting times excluded

>> Day 18b
benchmarking...
time                 2.166 ms   (2.081 ms .. 2.247 ms)
                     0.987 R²   (0.980 R² .. 0.993 R²)
mean                 2.166 ms   (2.106 ms .. 2.224 ms)
std dev              203.9 μs   (155.9 μs .. 269.6 μs)
variance introduced by outliers: 65% (severely inflated)

* parsing and formatting times excluded
```



Day 19
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day19.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d19p]* / *[Code][d19g]* / *[Rendered][d19h]* / *[Standalone Reflection Page][d19r]*

[d19p]: https://adventofcode.com/2020/day/19
[d19g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day19.hs
[d19h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day19.html
[d19r]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections-out/day19.md

I had originally solved this puzzle using recursive knot tying and a funky
custom Monad --- the writeup for that is [available online
here](https://github.com/mstksg/advent-of-code-2020/blob/5065aad720f6996386e9c94fbd7904a6fa9f2d9d/reflections-out/day19.md).
But after some thought and reflection, I saw that things might be a little
cleaner as a hylomorphism from
*[recursion-schemes](https://hackage.haskell.org/package/recursion-schemes)*,
so I did a rewrite based on it!  It also ended up being about 25% faster to
run, which was a nice bonus.  Note that I do have a [blog post on hylomorphisms
and recurion schemes]()
(https://blog.jle.im/entry/tries-with-recursion-schemes.html), if you'd like to
investigate more about the topic :)

The central type ("base functor") is `Rule`:

```haskell
data Rule a = Simple Char
            | Compound [[a]]
  deriving (Show, Eq, Ord, Generic, Functor)
```

A `Rule a` is either a "base" `Char` match, or it is a list of options of sequences
(a list of "or"'s of "and then"'s) of `a`.  The choice of `a` gives us
our interesting behavior.

For example, our initial ruleset from the input file is a list of `Rule Int`s:
either they are a simple `Char`, or they contain a list of options of sequences
of rule id's (`Int`).  We can load it all as an `IntMap (Rule Int)`, where each
`Rule Int` is stored under its rule ID.

Just to help us get an intuition for this type, let's look at what happens if
we want to "expand" out a rule all the way to only leaves at the end of a bunch
of nested choices and sequences.  This isn't required for the solve, but could
be pretty fun.

For that, we can use the `Fix` data type:

```haskell
newtype Fix f = Fix (f (Fix f))

type ExpandedRule = Fix Rule
```

A `Fix Rule` is infinite nested `Rule`s: it's essentially `Rule (Rule (Rule
(Rule ...)))` forever, meaning underneath each `Compound` are new rules, and at
the end of it all we only have `Leaf Char`s, and no more `Int`s.  For example,
we could represent rule 0 of

```
0: 1 2 | 3
1: 3
2: 3 3
3: "a"
```

as

```haskell
Fix $ Compound [
    [Fix $ Compoud [[Fix (Leaf 'a')]], Fix $ Compound [[Fix (Leaf 'a'), Fix (Leaf 'a')]]]
  , [Fix (Leaf 'a')]
  ]
```

But, given an `IntMap (Rule Int)` (the "unexpanded" raw rules as they are in
the input file), how do we get our `Fix Rule`?

We can use the handy `ana` function, which, given an expansion function `a ->
Rule a`, returns a `a -> Fix Rule`: It runs the `a -> Rule a` expansion
function on the "seed" `a`, and then runs it again on all the `a`s in the
result, and again, and again, etc., until there are no more `a`s to expand.

Well, in our case, our "expansion" function is `Int -> Rule Int`: "To expand an
`Int`, look it up in the `IntMap Int (RuleInt)`".  And that gives us a function
to fully expand any rule number:

```haskell
expandRule :: IntMap (Rule Int) -> Int -> Fix Rule
expandRule rs = ana (rs IM.!)
```

Neat, huh?  That will fully expand the rule at any index by repeatedly
re-expanding it with `(rs IM.!)` until we are out of things to expand.

Another fun thing we can write that we could actually use for part 1 is to turn
an `Fix Rule` into a list of all possible strings to match.  We want to
write a `Fix Rule -> [String]` function by tearing down our recursive data
type, and this could be nicely expressed with a catamorphism (`cata :: (Rule a
-> a) -> Fix Rule -> a`), where we specify how to tear down a "single layer" of
our `Rule` type, and `cata` will generalize that to tear down the entire
structure.  I talk about this a bit [in my recursion schemes blog
post](https://blog.jle.im/entry/tries-with-recursion-schemes.html), and the
explanation I give is "The `a` values in the `Rule` become the very things we
swore to create." --- in this case, the `[String]`

So let's write our `Rule [String] -> [String]`:

```haskell
generateAlg :: Rule [String] -> [String]
generateAlg = \case
    Simple c   -> [[c]]                                   -- the single single-char string is created
    Compoud xs -> concatMap (fmap concat . sequence) xs   -- concat/sequence all options
```

And now `cata generateAlg` will generate all possible matches from a ruleset

```haskell
ghci> cata generateAlg
    (Fix $ Compound [[Fix (Leaf 'h'), Fix (Leaf 'e')], [Fix (Leaf 'h')], [Fix (Leaf 'q')]])
["he","h","q"]
```

Okay, that's enough playing around for now...time to find our real solution :)

Note that we can "interpret" a rule to match it on a string by turning it into
a `String -> [String]`: it'll take a string and return a list of the leftovers
of every possible match.  For example, running the rules `(he)|h|q` on `"hello"`
*should* give us `["llo","ello"]`.  Then we can just see if we have any matches
that return empty leftovers.

For aid in thinking, let's imagine turning a `Fix Rule` into a `String ->
[String]`.  We can do that with the help of `cata :: (Rule a -> a) -> Fix Rule
-> a`.  Because we want to write a `Fix Rule -> (String -> [String])`, our
catamorphism function ("algebra") is `Rule (String -> [String]) -> (String ->
[String])`:

```haskell
matchAlg :: Rule (String -> [String]) -> String -> [String]
matchAlg = \case
    Simple c -> \case
      []   -> []
      d:ds -> if c == d then [ds] else []
    Compound xs -> \str ->
      concatMap (sequenceAll str) xs
  where
    -- run the String -> [String]s on an input String one after the other
    sequenceAll :: String -> [String -> [String]] -> [String]
    sequenceAll s0 fs = foldr (>=>) pure fs s0

match :: Fix Rule -> String -> [String]
match = cata matchAlg
```

We want to fail on our input string (return no matches) if we see a `Simple c`
with either an empty input string or one that doesn't match the `c`.  Then for
the `Compound` case with our `xs :: [[String -> [String]]]`, we take a choice
(`concatMap`) of all of the possible full sequences of the inner `[String ->
[String]]` sequences.

```haskell
ghci> match (Fix $ Compound [[Fix (Leaf 'h'), Fix (Leaf 'e')], [Fix (Leaf 'h')], [Fix (Leaf 'q')]])
                "hello"
["llo", "ello"]
```

Alright, so now how do we solve the final puzzle?

It looks like we need to "generate" a `Fix Rule`, and *immediately* tear it down
into a `String -> [String]` to use it to match a string.  "Generate recursively
and immediately tear down recursively"...that's a hylomorphism!

```haskell
hylo :: Functor f => (f b -> b) -> (a -> f a) -> a -> b

-- which we use as...
hylo :: (Rule b -> b) -> (a -> Rule a) -> a -> b

-- which we use as...
hylo  :: (Rule (String -> [String]) -> (String -> [String]))
      -> (Int -> Rule Int)
      -> Int
      -> (String -> [String])
```

If we give `hylo` a way to "break down nested `Rule`s" and a way to "build up
nested `Rule`s", then it can actually iteratively expand up `Rule`s while
immediately tearing them down.  The nice thing about this is that it's
very lazy: it'll only *call* the generator function if you ever *need* the
thing during your teardown function.  Since our teardown function (the `String
-> [String]`) will terminate whenever we encounter an empty string or no
matches, `hylo` will only run the build-up function until the point that we hit
one of those conditions.  You can also think of it as running it on a `Rule
Int` where each `Int` is dynamically looked up as you need it from the rules map.

The neat thing about this is that we don't ever need `Fix` at all: it's all
built up and torn down "in-place", and we never built up any intermediate
value.  That's why I mentioned that the `Fix` part earlier was more of a
side-tangent!  But it definitely helps us understand the big picture, I feel.

Our final code (the whole of it, minus the parser) ends up being:

```haskell
data Rule a = Simple Char
            | Compound [[a]]
  deriving (Show, Eq, Ord, Generic, Functor)

matchAlg :: Rule (String -> [String]) -> String -> [String]
matchAlg = \case
    Simple c -> \case
      []   -> []
      d:ds -> if c == d then [ds] else []
    Compound xs -> \str ->
      concatMap (sequenceAll str) xs
  where
    sequenceAll s0 fs = foldr (>=>) pure fs s0

matcher :: IntMap (Rule Int) -> String -> [String]
matcher rules = hylo matchAlg (rules IM.!) 0

solver :: IntMap (Rule Int) -> [String] -> Int
solver rules = length . filter (any null . matcher rules)

part1 :: IntMap Rule -> [String] -> Int
part1 = solver

part2 :: IntMap Rule -> [String] -> Int
part2 rs = solver (extraRules <> rs)

extraRules :: IntMap (Rule Int)
extraRules = IM.fromList [
    (8 , Compound [[42],[42,8]])
  , (11, Compound [[42,31],[42,11,31]])
  ]
```

As a nice little bonus, we can also use `generateAlg` with a hylomorphism to
also turn an `IntMap (Rule Int)` into a list of all possible strings, which
works for part 1 but would return an infinite list for part 2.

```haskell
generateAll :: IntMap (Rule Int) -> Int -> [String]
generateAll rules = hylo generateAlg (rules IM.!) 0
```


### Day 19 Benchmarks

```
>> Day 19a
benchmarking...
time                 4.597 ms   (4.283 ms .. 4.936 ms)
                     0.970 R²   (0.949 R² .. 0.989 R²)
mean                 5.142 ms   (4.951 ms .. 5.500 ms)
std dev              766.3 μs   (401.8 μs .. 1.260 ms)
variance introduced by outliers: 79% (severely inflated)

* parsing and formatting times excluded

>> Day 19b
benchmarking...
time                 31.11 ms   (27.26 ms .. 35.16 ms)
                     0.966 R²   (0.933 R² .. 0.998 R²)
mean                 30.22 ms   (29.51 ms .. 31.33 ms)
std dev              1.980 ms   (991.8 μs .. 3.197 ms)
variance introduced by outliers: 22% (moderately inflated)

* parsing and formatting times excluded
```

